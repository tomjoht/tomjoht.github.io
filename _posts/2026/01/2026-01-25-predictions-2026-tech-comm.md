---
title: "Podcast: Tech comm predictions for 2026 (Phase One - Fabrizio Ferri Benedetti and Tom Johnson)"
permalink: /blog/predictions-2026-tech-comm-podcast
date: 2026-01-25
categories:
- technical-writing
- podcasts
keywords: 
rebrandly: https://idbwrtng.com/predictions-2026-tech-comm
description: "In this episode, Fabrizio and I discuss our predictions for tech comm in 2026, focusing on two posts:  Fabrizio's <a href='https://passo.uno/my-day-tech-writer-2030/'>My day as an augmented technical writer in 2030</a> and my <a href='https://idratherbewriting.com/blog/tech-comm-predictions-for-2026/'>12 predictions for tech comm in 2026</a>. Some of the specific topics we cover include the evolution of writers into automation engineers, the increasing necessity of systems thinking, the economic paradox where high tech valuations are contrasting with stagnant hiring, the risk of the Reverse Centaur dynamic (where humans merely approve AI output), and the growing value of authentic human connection and humanity."
podcast_link: https://dts.podtrac.com/redirect.mp3/s3.us-west-1.wasabisys.com/idbwmedia.com/podcasts/phase_one_episode5predictions.mp3
podcast_file_size: 56
podcast_duration: "01:02:04"
podcast_length: 56038237
image: thumb-fabrizio-tom-episode5.png
---

* TOC
{:toc}

<iframe width="560" height="315" src="https://www.youtube.com/embed/gzF0ZiBCXVo?si=UloVOWc0S8JmSd42" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

## Audio only

{% include audio.html %}

## Key takeaways

Here are some takeaways (AI-generated) from the podcast:

* **We are currently in "Phase One" of the AI era.** Fabrizio characterizes this period as a "wild west" of early adoption and experimentation. He predicts that heavy regulation and standardization (similar to GDPR or safety standards in other industries) are inevitable and will define the next phase, though Tom expresses skepticism about how effective global regulation can be given the competitive race with other nations.
* **The AI hype cycle will likely plateau in 2026.** Tom predicts that the initial "champagne popping" excitement will fade as companies realize that AI implementation is harder than expected. The "human in the loop" bottleneck&mdash;the need for humans to review and verify AI output&mdash;will slow down the dream of full automation.
* **Technical writers must evolve into "automation engineers."** The role is shifting from writing content from scratch to orchestrating and scripting AI agents to perform tasks. The value you bring will be in your ability to build the systems and workflows that allow AI to generate documentation, rather than just writing the words yourself.
* **Beware the "Reverse Centaur" scenario.** Fabrizio warns of a future where humans become mere "approvers" or "button pushers" for AI-generated work&mdash;a "reverse centaur" where the AI is the head and the human is the body. He argues that we must fight to retain human agency, creativity, and high-level decision-making to avoid this demeaning outcome.
* **Human connection will become a premium commodity.** As AI floods the web with "slop" and generic content, Tom and Fabrizio predict a counter-movement where people crave authentic, human voices. Personal blogs, podcasts, and communities that offer genuine connection will become more valuable as people seek to escape the loneliness of an AI-mediated world.
* **The "P-Doom" fear is shifting.** The existential dread regarding AI is moving away from the sci-fi "Skynet/AGI sentience" scenario and toward a more pragmatic fear of bad actors using powerful AI tools for malicious purposes (for example, cyberattacks, bioweapons, or massive disinformation campaigns).
* **Hiring may remain stagnant despite market growth.** There's a paradox where tech stocks are soaring, but hiring is frozen. Companies are in a "wait and see" mode, hoping AI can replace headcount, which may lead to a "jobless recovery" in the tech sector for the near future.
* **Apple will likely mainstream "emotional" AI.** With its focus on privacy and on-device processing, Apple is positioned to introduce AI that feels more personal and "human" to the average consumer, potentially leading to a "Her"-like scenario where people form emotional attachments to their AI assistants.
* **The "Human Certification" need.** As it becomes impossible to distinguish AI text from human text, we may see a rise in demand for "proof of humanity" or certification systems that verify content was actually written by a person, similar to "organic" labels for food.

{% include ads.html %}

## Resources

- [My day as an augmented technical writer in 2030](https://passo.uno/my-day-tech-writer-2030/)
- [12 predictions for tech comm in 2026](/blog/tech-comm-predictions-for-2026)
- [The four modes of AI-augmented technical writing](https://passo.uno/four-modes-ai-augmented-tech-writing/)
- [Tech writing webring](https://caseyrfsmith.github.io/webring/)

## Transcript

Here is the transcript of the podcast episode, formatted for your show notes.

**Tom:** Welcome to another podcast with Fabrizio Ferri Benedetti and Tom Johnson, your two hosts. My blog is idratherbewriting.com, Fabrizio's is passo.uno. And this podcast is one where we explore the intersection of TechComm and AI. We've been thinking about different ways, different names for this, and going to experiment with a name called "Phase One," representing that this is like an early phase of how TechComm and AI intersect. We'll see if that sticks.

But anyway, welcome Fabrizio. Thanks for joining. We got lots of great stuff to talk about. Anything you want to say just to introduce, I don't know, to say hello to people?

**Fabrizio:** Yeah, well, happy belated new year. It's been a while. But otherwise I'm pretty excited about what 2026 might hold. So yeah, let's talk about it.

**Tom:** Yeah, so you have a mood of optimism. I like it. I like it. You know, in 2026...

**Fabrizio:** I try. I say it's... you know, I wrote that there was this talk at Write the Docs Berlin last year and it was all about optimism and like the fact that optimism is a duty, as some philosophers used to say. And I really believe in that. Like I think we ought to be optimistic, which doesn't mean we have to be like blind to change or, you know, avoidant of what's obviously negative. But I think we shouldn't like just give up yet on things. So...

**Tom:** Yeah. Well I think we have a lot to be optimistic about. I mean we are in a singular point in history where nothing has ever been this way since the dawn of tech writing. It's a transition point. And what a time to be in the field. What a time to be a tech writer. When everything is changing.

I was driving this morning and thinking about how I haven't changed my role in my org, I haven't changed my professional title for since I started, like 20 years ago. I've been in the same spot at least five years and everything around me has changed. And now it's like tech writing is moving into automation engineering type stuff. It's like totally different. You're an orchestrator, a context curator. You're doing something totally different. And my org, the tools have changed, my management chain has changed, the focus has changed, the products have changed, the partners have changed. Like everything. Locations where I sit, everything. It just... yeah, anyway.

**Fabrizio:** But we're still there. So there might be something to what we do that doesn't get old.

**Tom:** Yeah. Well hey, we're going to look at a very hot topic, okay? Now among in the blogosphere, the number one most popular topic every year is predictions. I don't know why, but like people love predictions. And for some reason it's like the sweet spot for any blog and podcast too. And just I was just looking at the metrics for my predictions post, "12 predictions for TechComm in 2026." And it had like three times as many clicks as any other post. And I really like yours. You have such a unique take. I don't think I gave it enough credit the first time I was reading your post, "My day as an augmented tech writer in 2030." But I have been unpacking it. And there are so many details that I find fascinating in this post.

**Fabrizio:** Yeah. Like what? Like what? Tell me about it.

**Tom:** The number one thing that stands out to me is that you seem to... you... okay, so let me just give a little context. "My day as an augmented tech writer in 2030," Fabrizio took the position of imagining what it would be like to be a tech writer in 2030 and he describes that person's day. So you don't have straightforward like "hey, I predict this will happen and this will happen." It's more like you have to unpack it based on what's going on. And the thing that jumped out at me most was that you envision a world where things are regulated. Kind of highly regulated. This is in contrast to my post where I thought that this race with China is going to make it so we just tear down any guard rails about regulation. And now you're in Spain and I'm in the West Coast. So probably have totally different environments. But can you tell us... tell me a little bit about what are your thoughts on regulation? You think AI is actually going to be regulated or is this just going to be free for all, no holds barred, you got to compete in any way you can?

**Fabrizio:** Yeah, I think... you know, of course I wrote this as a kind of pun maybe from the Europe, European side of things perspective, you know. But I think that wave is coming at some point. Because everything else in tech right now is regulated in some way or another. You know, like for example you have SOC2 in IT that you have to comply with pretty much everywhere. So we're not just talking about GDPR or European laws, but it's also legislation in the United States and other places that you have to follow eventually. But those things usually happen naturally. We are still in Phase One. So, you know, and in this phase is like when any new tech is introduced there's a period of time where legislators are kind of clueless. Things haven't happened yet or are still happening and decisions haven't been taken yet. And law usually moves a lot slower than tech. But then it catches up. And I think it will catch up eventually.

And people, you know, as this becomes more pervasive and more abundant and more accessible—which I hope will be the case, you know—I really wouldn't like to see a world where AI is exclusive or you know, something that very few people can use. I would hate that. That's the worst case scenario. But in a scenario where everybody can use AI, definitely, you know, they will need to... they will start being consumers. And consumers, right, are a thing everywhere, even in China. So they will start asking for traceability. They will start asking for "where is this information coming from?" And eventually we will get to a point where there is some... where the regulation, where something stamped on top of the AI is something that will make people feel better.

And I'm not talking just about regulation but also I think I hinted at that in the post is pedigree. We will want to know where the models come from and you know, who are their daddies, you know, father and mother, who created them, what data they used to train the model. Because that will... we will have like model connoisseurs, you know, much like it happens with wine, you know. Like, "Oh, this model was trained on on the Library of Congress stuff or whatever and it's oh, good quality, good stuff," you know. So that's my take. Of course it's optimistic, but I think regulation will be mostly positive and happening I think.

**Tom:** Hmm. Yeah, well I mean I would love to see regulation have more teeth and be something that plays out. So that's definitely an optimistic point of view. Certainly I don't want to live in a world where hackers have destabilized every financial system because with AI they can crack all the passwords, they can make it so no system is safe. You know, even your nuclear codes are like being hacked. Yeah, I just... that's not so great, right? Like we need safeguards.

**Fabrizio:** Yeah, no, that would be like the Doomsday scenario that you were predicting maybe in your post or the P-Doom thing?

**Tom:** Man, did I... You know, okay, so I think what I was trying to say with the P-Doom is is it's going to shift a bit. Yeah. I think this... I just don't really buy the idea that the AI is going to wake up and one day become sentient and be like, "Oh, whoa, I'm real," you know? I think instead the P-Doom is going to shift towards, "Oh my god, people are building bioweapons or people are building like killer drones." You've got small anarchist armies that are having outsized influence with their killer drones being pointed towards, I don't know, some political entity. Or some more concrete bad thing happening because of AI, but not due to computer sentience. And I don't know that we've experienced that event yet. Maybe I just am naive, but definitely like... yeah, I'm not a huge believer in the sentience conscious part of AI. I don't know. What do you think about that? You obviously... okay, so you position... this was even the larger takeaway from your post. You position your imagination in 2030, which is one year past when Kurzweil and others predict that AGI will be in place. So you don't really see AI becoming or AGI taking hold in 2029?

**Fabrizio:** No, no, no. Like I mean I think the same as Yann LeCun for example at Meta and other most AI experts, research centers and universities. If you ask about this or neuroscientists, they will tell you it's nigh impossible. Like it's... I think some use the this metaphor of "you're not gonna get to the speed of a train just by making bigger horses," something like that. You know, it's... there's like a qualitative step that essentially you cannot get that using a Large Language Model. You get a semblance of that, but you cannot get the agency, you cannot get the general intelligence. And I think most vendors have already given up on promising that. So we would need like something radically different to get there. But then I don't even think that's desirable. Like to be honest, it's nice maybe for a sales pitch, but I don't think we need general artificial intelligence right now. Like it's... we probably need like better human intelligence, but that's maybe separate topic. But you know, so yeah, I don't think... but that's... I mean we won't get there, but it's fine. And even if we got there eventually maybe 50 years from now, I don't know, I would probably like just let it run the country or something. But yeah.

**Tom:** Yeah. Well writing on this same theme, one of my predictions is that the hype around AI is going to kind of level off a bit because I was looking at my own yearly statistics and the previous year I did see a pretty big bump as I started to really use AI. I felt like my stats seemed to double. It's hard to really be exactly scientific because there's so many different factors. Site migrations, new APIs, new whole doc sets I'm pushing out kind of messes up my stats. But I did definitely feel like I saw at least my productivity double if not more when I embraced AI.

But then just this past year, I saw maybe 10% more, maybe maybe the same. So I think that this initial kind of champagne popping attitude where people are like, "Oh my god, look how fast this is going, we're going to automate away everything in a few years, all the roles will change." I think that's going to die down and people are going to be, "Oh, okay, so I am faster but there's a limit because as much as I generate all this stuff, I still have to review it. I'm not just pushing out... nobody's pushing out docs without reviewing them, same with code." And that creates a natural speed limit.

**Fabrizio:** Yeah. I mean in my case I can tell you that AI has certainly increased my productivity. But it also has like opened up new ways for me of contributing. So it's like a... it's not just a force multiplier, but it's also a multiplier of things you can do. And at times I felt like this... this itch, you know in the back of my head, like: "Well you have these new capabilities, you have these augmentation, you can do so much more." And there are times where you feel kind of guilty of not doing something. Because it's like, "I could be doing more, you know. I could be maybe fixing this stuff or why I haven't thought of using these and these other tool together?" And which is a weird feeling. It's a weird feeling of... you know, I could do more. But this connects back to one thing that we brought up in a previous podcast which is limits. You know, like before we start using these tools for anything, before we start like working in an augmented state, we need to know where we want to get. And then do not get like beyond that point because otherwise there's no there's no end to work. There's no end to it, you know. And it's not healthy.

**Tom:** Your comment about doing more made me think about some recent experiences I had at work doing more. I was publishing some reference docs and I noticed there was some weird code appearing in it. And I reached out to the team who owns the sort of Javadoc piece of it. And yeah, ended up fixing the problem. They had some reverse false true statement or something. It was not that big of a deal, but like AI honed in on it, fixed it and I committed the the fix, right? Which is not something I'd usually do. That's like an engineering ownership. And same thing happened with a different tool where like the output was weird and there was a problem in the engineering code. I had no idea what it was but some kind of package permissions problem and fixed it. And I was like, "Holy crap, you know, it's like I'm much more capable than I thought past."

**Fabrizio:** But then you wonder so where does this end? Like how many more problems could I fix? And we as tech writers have lots of visibility of what's broken out there, you know. Yeah. But then in my blog post if you remember, the AI assistant called Chuck in the post, it has these safeguards, you know. At some point it tells you like, "Why don't you stop and go for a walk?" Or you know, and it checks the vitals on the smartwatch and is able to call like emergencies if needed. And this is like the kind of feeling I had sometimes with Claude for example when I reached the token limit and it says, "No, you cannot work till 20," and I'm like... 8pm... and I'm like, "Okay, okay, so I might go... I can go for a break." But I would like this not to be related to token exhaustion, like something more like a healthy, you know, like the AI assistant telling you to to stop a bit, you know, and try to help you keep like a healthy balance. But...

**Tom:** I liked that. I liked that. I mean at first I was like, "What, you know, the computer's never going to tell me what to do." But for sure if like we can take all of our biodata and just get it integrated with some kind of smart AI assistant that can understand this patterns of all this data especially as we're interacting with a computer. Sure, I would love to know. I think just even in looking at the eye patterns people can tell if somebody has ADHD or not. It's like that's pretty clear. But yeah, all kinds of other stuff.

**Fabrizio:** Yeah, but is this still connected to something that I don't know if we'll see improvement this year. I don't feel optimistic... that's something I don't feel particularly optimistic about is UX. The UX of AI. And I think there still are too many modes of interaction with AI. I recently wrote about that in my blog post, my latest blog post. And we really need to come up with... like too many tools, too many players. This is again is Phase One problem. Like there's an explosion, eventually there will be like a reduction of, you know, like the playing field will get smaller, will adjust. But in the meantime, people don't know, you know: "Am I going to use a skill or am I going to set up an MCP server?" Or you know, and everybody have different experiences. So how... you want to use AI, fine, but where do you start? You know, where do you... I recall that when I first read your API documentation tutorial, I mean there was OpenAPI. That was pretty much about it, you know. Most adopted API specification standard. There were maybe a few others but they weren't like popular or anything. And that was like a path to quick adoption. In our case right now, that's not really clear, you know.

**Tom:** Yeah, just to reference the post you're talking about. So this one, your most recent one is called "The four modes of AI augmented technical writing." And you're saying that like you've got a lot of different surfaces where AI sort of you interact with it. One is like you're in your editor and it's suggesting things as you type. I think you called that whisper mode or something. Anyway. You've also got the chatbot like a water cooler where you ask questions and get things back. And then another mode was like you're doing some kind of automation at the larger level where like one action...

**Fabrizio:** The Disassembler where... yeah, where you have like sub-agents doing different things at the same time. Yeah.

**Tom:** Yeah. And then there was one more, I can't remember. But for sure I agree with you that there are so many different touch points. I mean gosh, at my work there are AI integrations everywhere. Your weekly report about what you've done, you can get that email to you. Every day I arrive and I've got an email from some agent that has looked through my inbox, my chat messages and tries to tell me what I should be doing. I'm like... I usually just ignore that one. I'm like...

**Fabrizio:** Like I use a trick for example that I discovered the other day which I hadn't think about is you have the GitHub command line, you know, the GH command. And if you use cloud code with that tool, you can do things like for example: "I have this document I want to create like... chunk these work streams in a number of issues and create sub-issues in GitHub for me using the API." You know, bam. And it does that. Like it's all of a sudden the bureaucracy is done with a command. And I plan on doing things like for example similar to what I described in the post like: "Okay, check the project board and tell me what's going on." And it uses the GitHub command to access the API, fetch the information, try to detect a pattern and say, "Well these are the priorities Fabrizio, like this is on fire," or something like that. And I'm really looking forward to things like that. But again, you know, this can only be done when for example from an IDE I wouldn't probably do it. It's more efficient when done from the CLI. But then how do people know this? You know, it's like you have... it's trial and error or coming up with secret combos recipes. It's not obvious. Most of this stuff is not obvious right now.

**Tom:** I'm seeing AI just baked into every sort of interface just as like an option. And this might be a Google specific thing. But for example in our bug tool there's a button. In our browser there's a button. In our code repo there's a button. In our IDE there's a button. In the CLI there's an option. It's pretty much just there and it's all kind of... a lot of it's using a similar model but... For example when I create a change list, there's a button to review it with AI. And I love that thing. It like... I think it just kicks off a prompt that says "check for unexpected changes." But about a quarter of the time it finds stuff that I missed. And so yeah I think that there's definitely like a fatigue and a confusion and an overwhelm, sense of overwhelm with so many different tools. In our internal AI sort of education group, definitely experienced a lot of fatigue where people are like, "Oh my god, yet another tool." I think I mentioned this previously but the CLI tool had come out, Gemini CLI, and one writer was really praising it. It was like it was amazing. And then she went on vacation and the next month it was like, "Oh, Antigravity is out." It's like, "Oh this blows away the previous one." So yeah.

**Fabrizio:** Yeah. But there's a third option coming which is kind of scary if you think about it. Which is AI taking over your entire workspace. So I'm talking of things like I don't know if you've seen Cloud Code Co-Work or for example Manus AI is a tool that I've used recently for you know like some presentations and stuff like that. Personal level, not work. And Manus specifically spins up this small Linux computer and it does all the work on that small computer. It spins off like a virtual machine. So it has like full control of a whole, you know, computer to do stuff. And Cloud Code Co-Work is essentially is the same thing but on your computer. Which is an extension of for example the browser extension they launched where it allowed Cloud to use your browser and control your browser. But so well, if you let that door open, I don't know how much content would that consume, probably a lot. But essentially it's like: "Well I don't need the button in different tools because now the AI has control of the whole thing." But yeah it's... I don't know if I'd allow that to be honest.

**Tom:** Wow, I have not experimented with that. And I've heard about it. So wow, that's pretty interesting. Yeah. You sort of mentioned something in your post... I'm trying to remember exactly. Like a reverse Centaur where the AI is doing 80%...

**Fabrizio:** Yeah that's Cory Doctorow... the writer wrote a fantastic article about that. And it's like... the Center is like the best scenario. It's like human upper torso with the body of a horse. So you go fast but you retain your human intelligence and control. The reverse Centaur is like well essentially you have the worst of both worlds. So you are like an approver, like just a machine... like a human appendage of AI. AI is doing the stuff and the human is just clicking a button saying "Yeah go ahead." And it's really demeaning of what is human, you know. So that's of course is the apocalyptic scenario. And I think Cory Doctorow is a science fiction writer and he does that very well as being, you know, I love him. But he's like kind of what he does, right? Is painting these scenarios for us. My take is still optimistic in that we can avoid that mostly for the most part. Or at least sometimes we'll be reverse Centaur and it's fine. Some other times we'll take more control. You know, it's something like that.

**Tom:** Yeah, there's a lot of fear that people have that they're going to lose their writing skills because they are adopting this inverted Centaur. They're no longer really calling the shots. They're as you say kind of approving things, looking it over. It seems right. Like I don't... And so people are worried that what exactly is going to be our value? Our role is diminishing. Or like the human aspect of it is diminishing. Now in your predictions post, you had the writer have some kind of certification on content that it was like human... human certification about how much AI was used. So you still see like the human in control? You don't see the human being marginalized in a really extreme way?

**Fabrizio:** Oh I mean... of course there will be cases where this will happen, you know. Because it's... like misuse of technology will always happen. But in general I think there are already like attempts out there, which are very clever by the way, of certifying that something was written by a human. For example, I don't remember the name right now, but there's this encrypted certificate that is generated to for example a blog post. How does that work? Well essentially you have like a program running in the background of your computer registering your keystrokes on the keyboard of your computer and hashing that. And then you present the text and it says, "Well you haven't typed any of this." So you cannot really certify you typed that. But it's all encrypted so there's no data leaking anything. But it's just checking the two activity hashes together so that you can certify whether that came out. And well it really depend on what we value, right? Like maybe 50 years ago nobody valued like green food bio whatever sustainability. Now we do. And I think you know the same will happen with human generated content. But in tech writing, I don't know. Like I'm expecting that people will value having like a human talking to them and explaining things to them.

**Tom:** I don't know exactly if I see a demand for that. I have... I use AI to write plenty of stuff. I will usually put a little tagline in my change list saying "hey this is AI generated so review it carefully because uh if there are errors I'm hoping you catch them." I don't quite say that last part. But I don't get people pushing back and being like "oh my god not another AI generated AI written stuff."

However, in the expressive writing space on a blog, it's a lot different. There's definitely a pushback against AI slop. It's a totally different genre. So like AI is killing it in the enterprise where prose is voiceless, there's no byline, there's no like "hey what's your argument here" or "what's your... add a little bit more of your personal experience and perspective." Now nobody's ever asked me that. They're just like "hey is this accurate?"

And I don't even think people are going to be reading enterprise written tech docs anymore. They just want the file and they want to query it in their own AI tool. They want... this is what people really want. People cannot figure this out in the enterprise. They want to make it so that somebody who goes to ChatGPT, Cloud Code, Gemini, something else... they get all the comprehensive accurate documentation information. We might be able to influence Gemini, but how could we possibly influence ChatGPT? You know? How do you do that? So if you somehow make your content completely portable with an MCP server, it sort of addresses that. And I think that's what most people are going to want. Nobody wants to read docs.

**Fabrizio:** Probably. But you know I remember when you wrote that blog post about the feeling of loneliness at work, you know, and not being... Yeah, and there's a previous post to the one I wrote which is "Technical Predictions for 2049." And my prediction there was a bit wilder in that I think technical writers will be like therapists of AI. Or you know like the non-player characters in massive role playing games, you know like the shopkeeper. Because I expect people at some point will want that truly human contact. You know of someone that explains tech to them. And it's already happening like in the DevRel space. You know you see the videos of tech influencers explaining tech in a very human way, you know in a very relatable way as if they were like at a campfire or something.

I don't know if that is scalable of course. But I mean in the end why some companies are successful in selling stuff is because they have fantastic sales representatives, account executives. Like real humans that go there and be human with other folks and explain stuff like directly. And they use our docs, you know for that. So the human ingredients somehow will surface. But my only concern is how many of us will be needed for this. And I don't know if a lot of us will be needed for this to be honest. You know like I don't know.

**Tom:** Sorry I have to smile about that that post I wrote on loneliness and how that's going to increase. Because I just heard back from one of my academic friends, Professor Jeremy Rosselot-Merritt who teaches at James Madison. He said that he put that post along with this predictions post and something else... his guest post he wrote... into his TechComm curriculum for the year. And I got so much responses from that loneliness post. And I don't know why. Maybe it's because people really connected with something. Like there's a lot of lonely tech writers out there. And they're like "oh my god even this guy who's got every connection and seems to be surrounded by so many people is also feeling isolated and lonely? That's crazy."

But but yeah I do think in my own blogging I'm trying to emphasize the human elements. What is my experience? What is my opinion about this? Bring that in. And not... definitely don't want to let AI take over those elements. Whereas maybe having AI do some summary, some fact checking. Am I interpreting this article right? Did I get this book correct in terms of how I'm depicting the author's argument? That kind of stuff is really good with AI.

But yeah AI... it's not only got problems with like first person kind of elements but the language too is too tame. It's too middle of the curve. You need the edges. The alien stuff. This is a post I'm working on. I've got a big theory about Bakhtin and Heteroglossia that I'm dying to to share. Probably will only resonate with a few nerds out there but... definitely language is a problem too. But anyway.

But this podcast is mostly about enterprise tech doc writing. And do will we need the human? I don't know. That remains to be seen. However let me shift to a slightly different sort of idea. So if our writing skills are not necessarily going to be championed and sought after, what are the new skills that people should really pursue? That's a question a lot of the academics are asking. How do we train our students? What are the skills that are in demand in the workplace?

And I predict that automation engineering will be a new skill. Learning how to write a script or a prompt that results in the system like achieving what you want. What do you think about automation engineering?

**Fabrizio:** I think automation engineering is is like an expression... one of the many expressions of systems thinking. Which I believe we brought up in previous podcasts as well. And I think systems thinking is one of the top skills I would probably seek in anybody in the future working with AI. Because it's really about orchestrating and seeing the big picture and relating systems between each other. Which is something that I don't expect AI ever to be able to do.

And automation... well you can also... there's always this thing about the automatons building themselves and I think AI can help you build parts of that automation system. But in the end how you connect the pieces together is entirely up to you. Because that's that's ultimately the system you build is an expression is of... and I'm getting philosophical here... of volition. Of something you want to do.

And wanting to do something is purely organic human. Like you want to achieve something that you care about. So yes I think definitely automation as a part of that system thinking definitely. The other I think is communication, you know in all forms. So and I think I was having this conversation with a developer the other day on BlueSky. He writes Python tutorials. And we were agreeing that anybody who has both the technical knowledge and the communication skills is like in the best position going forward in the tech world. Because you will need both. You will need like an understanding of what the tech does but at the same time like a certain command of words.

And I would argue that 60 or 70 percent going forward.

**Tom:** I really like your connection of automation engineering with systems thinking. I hadn't actually thought about those two but you're absolutely right. Like you have to understand this larger system. That was a topic systems thinking was something I was really kind of interested in a couple years ago and then it fizzled out because I for various reasons. But yeah I like that.

You know I was giving a leading a discussion about automation engineering internally at my work the other day. And I realized something. Not a lot of people are doing this. Like they're... I was trying to find people in our community who had like automated entire processes and been like "yeah I scripted this really complex thing and now it's like Gemini does it." And there were a couple of people who had done some cool things but nothing no large scale trends.

And I think I'm pushing the boundaries in trying to automate my release notes process which has a lot of different pieces to it.

But my larger takeaway here is that all these fears about a tech writer role being automated away are kind of ridiculous if we can't even automate a single process that that role performs. If it's so hard to just automate release notes, how are you ever going to automate the entire role of the person? It might be the case that we can only automate tasks and subtasks within processes and we really need a lot of the cyborg type collaborative iterative back and forth between human and machine. Maybe that's the really only viable model. In which case our jobs should be safe. Anyway.

**Fabrizio:** Perhaps... the thing is if you try... you know from what I know is that if you try to create like an automated fully automated system with LLM in between, you will notice two things. One is that unless you have like an unlimited amount of tokens or AI credits or AI usage, it's pretty difficult because you essentially you're putting something that is not controlled in a place where it's going to consume context unsupervised. And we don't simply have that that much fuel in the machine for that right now. Like most AI agents have limited context, limited capabilities and no matter how many you spin, you will end up like hitting a wall.

So and deterministic automation can run at a very large scale. I'm not sure we can scale up. But that's like a temporary limitation probably. If hardware gets better, software gets better. So that's one thing.

And the other thing is that you really need to think about the limit where you're gonna... but that's also like a problem of general automation.

And that's the reason why I think is failing is because our domain is so undeterministic in a way. Like there are very few places in our documentation where we can for sure say "yeah this is gonna be always automated." Maybe code snippets is the only one that comes to my mind.

**Tom:** I'm separating my... when I try to automate something I'm separating the tasks into two different buckets. One is the deterministic part. For example with release notes I want to create file diffs of every changed API reference file in the release. You know but that's something I can script in a deterministic way. But then if I want to take and get a summary of the file diff and connect it to a roadmap item, that I can't write a script for that. But I can write a prompt for it. So then that gets filed under the probabilistic sort of task.

And this kind of pairing of "okay we're going to run the deterministic tasks get as far as we can and then we switch over into probabilistic mode and do the rest." But even in probabilistic mode I might have to run the same task like five different times until I feel confident that the response is is actually right. Uh if it's a complex thing.

**Fabrizio:** That's how agents operate right now and I think that's is the key to future AI based automation is make the AI part as small as possible and try to cover the rest of the area with deterministic stuff. So that for example if I want to check... and I'm currently using this... Chris Ward and I built this MCP server to check documentation style using Vale. And Vale is a fully deterministic tool. It uses rules, right? The thing is essentially you are telling the agent to use this tool to check for the style as many times as possible. But it's not doing it itself manually. So it's is the most is the surest way to combine the two.

**Tom:** I remember your post on that and that strategy is key. And for sure like I'm using AI to write the deterministic scripts. So so it's factoring in there but but yeah once the script is written it's hopefully not relying on any kind of AI. Exactly. Yeah well hey let's jump into another part of the predictions that is still kind of um I haven't quite figured out how I feel about it. Because I love coffee and you said that your future writer is drinking surrogate coffee because nobody can afford coffee anymore. And in my predictions I took an optimistic view and said the economy won't crash because AI is going to suddenly take hold in all kinds of non-tech domains. From the library to your police force to all the stuff that wasn't like AI saturated. It's going to find a home and that's going to buoy up enough of the revenues. But your world you can't even drink coffee. So what's up with that?

**Fabrizio:** That was just just the dystopian touch you know that you had to have like "we cannot have everything right." And back when I don't know what the situation is now, when I wrote that coffee prices were surging. I don't know if they are still quite high. But I mean those things will happen. And I think I wanted to add that touch in a way as a way of saying that you know bad things will still happen. The road will always be bumpy. But in general, in general there you know there will be moments of kindness and there will be moments of quiet. Um you know that's that's my way of of looking at it you know. Like the road is going to be bumpy but there will always be like a stop and and we can relax you know. That's yeah.

**Tom:** Well about the bumpy road, I think a lot of people in the industry are wondering if A) they should get into something else because they're not seeing a lot of hiring. They're not seeing a lot of hiring. However if you look at like hiring trends there is a group that is being hired and it's people with AI skills. Um I mean it's a lot easier to say than to develop right? But uh do you think that like if you're a tech writer who's out of work or your student looking to break into the field, if you specialize in AI you're going to find a home somewhere? What do you think?

**Fabrizio:** Um I think if you present your work as as something that benefits from AI augmentation and you can you know explain your workflows and and show the results of it, definitely. Definitely. But you know things like I think the approach is really showing what you can build using AI and and showing also like how much AI is broadens your your reach and the kind of things you can do. Like scripting or like creating systems using agents like Sarah Deaton recently wrote about in our blog. I will send you that URL later for links.

So but not like a you know not not the classic approach of "I have an AI certification" or "I did like AI courses." I mean that might work sometimes but everything these days is about doing and showing and telling people what you've done. And it's always been a bit like this in tech but I think is even more like that now because it's not a field that has solidified enough so that you can like get a degree on or something like that you know.

**Tom:** Yeah. Well this year I really want to emphasize more of like the automation engineering part of my role and develop that. So that's kind of my way of trying to push into that skill set. And if I can say "hey check out this script I wrote and here's what it did for... it wrote all the release notes and got like 90% there every time save me oodles of time." Maybe that will be a good skill. Hey let's look at one more prediction. You had a pretty controversial one in there where you said that Claude... Claude or Anthropic had gone bankrupt or had been purchased and acquired by Apple. And so Apple finally got some good AI in there. But it provokes this larger question of like in order for an AI company to survive, do they really have to adopt one of these like approaches where you've got a whole ecosystem of products? I mean think about Amazon, Apple, Google. Like they're not single product companies. Uh I don't know if you had any larger thoughts about like what an AI company will need to do in the future to survive.

**Fabrizio:** Uh it really depends on their aspirations. Like if you aspire at like you know... and I think we'll see that. Like we'll see players maybe shrinking to just target the developer space. And that would be fine because it's already where they have the biggest traction. Like Claude is is an example of that. Like they have one of the best coding models.

But if you if you really aspire at selling something to everybody, of course you need like a bigger surface and that is the biggest player have that. Maybe you know I don't know I'm you know like maybe by some feat of fiscal engineering some miracle there, government intervention, uh maybe we will see those companies still being you know still propelled into growth uh this year. But it doesn't look super rosy. Um I don't share the pessimism of of some you know pundits that you know say that everything is going to crash and it's going to drag us to the bottom of the sea. But um yeah I think the at some point the flow of money the flow of cash will will diminish and they will have to either specialize or you know pivot into something else. But yeah. So back to your question yes if you have an ecosystem of course you have an advantage. Yeah.

**Tom:** Yeah. And um gosh a lot of people just keep waiting for Apple to make like a winning move and and we'll see if that happens. It seems like they had so much cash to burn and I was excited for them to come out with a with a car. And then they scrapped that whole Project Titan effort and it bugged me. So hopefully they'll they'll make a good move.

**Fabrizio:** I think if if they're still true to their roots and and spirit, I think Apple struggle echoes our own struggle as technical writers. Because one of the things I would like to to think more about going forward starting this year is how to reconcile the human side of our work with with AI. And I think Apple has always had these human touch in their design system.

And I think they're still trying to figure out how to really make it like a very human experience like even an emotional experience. You know if they succeed we will probably... you remember the movie Her from 2013? I mean that's like how I picture like Apple AI going forward. But I don't know. Like that's a dream. That's a dream you know.

**Tom:** Interesting. I hadn't thought of like Apple being the sort of a metaphor for our own state and so on. The ability to combine human human excellence with the AI integration. And so yeah for sure they're going to they're going to find their transhumanist movement hopefully. You know they always been about the intersection of humanities and tech. Well we'll see if that holds.

**Fabrizio:** Yeah. Hey let's let's talk briefly about um something else you you wrote... you were trying to make an impassioned plea in a larger sense. You said "To those who fired or didn't hire tech writers because of AI." It's at passo.uno/reconsider. And you said this actually um got some attention on Hacker News among software engineers. So uh just curious tell me about this post why did you write it and what was your what was the reaction on Hacker News.

**Tom:** Yeah so you know I was uh you know uh it's been like a end of the year with hiring freezes you know you. I still I still I'm still going to Reddit to you know and read the thoughts of technical writers some of which are are a bit depressing because there's there's many uh many sad situations out there. Uh like even today there's a post of someone who who was like uh fired because of AI. And I was like well you know let's you know let's go on the offensive. Let's let's write something to that people. Let's address those folks who are taking those decisions. And you know with I I I I didn't have anyone in particular in my mind just you know anyone who might at some point consider doing something like that.

And so yeah that's writing impassioned stuff is something that I like doing and and AI isn't very good at doing. So uh I said why not.

And ironically I was using Manus AI um uh to to like try some layouts and it you know when I showed the post without saying anything Manus created these single page application that that then I used to in /reconsider. Uh and I thought well this is brilliant. I mean it's not my usual blog layout I can always post it in the blog but let's use this layout that is like feels like more like a manifesto kind of thing. Um and it kind of worked. And in Hacker News well the reactions I think most of them were were like empathetic with the message and and like a bit on the sad side and perhaps also feeling that this is coming to software engineering as well. Uh and then of course you you always have like the you know uh two or three trolls but that's what you know that's to be expected on Hacker News anyway.

Uh but apparently these also got like uh some resonances even like in uh there's a newsletter uh for recruiters uh apparently and you know the the the post got mentioned there. So it kind of got you know the attention of the people I wanted to to read it. Uh we'll see I mean it's just a drop in the ocean but um I I really wanted to to crystallize like the kind of mood we need to have like to fight back against you know thinking that we can be replaced easily. And I think we have lots of arguments you know.

**Fabrizio:** I first of all I I when I read that post I thought oh Fabry has like redesigned his blog and he's got a way more stylish... And then I saw then I went to passo.uno was like oh this is like a one-off styling. Because it is it is extremely well done and that adds to the ethos of the post for sure. Um I like.

**Tom:** But isn't it ironic that AI helped me design that you know like it helped me get the message through that yeah of course you don't want to use me like let me help you with that.

**Tom:** Well this topic reminds me of something my previous manager told me. We were talking about like what can you do to try to dissuade senior execs from getting this idea that tech writers could just be replaceable by AI. Um and he said that I could have influence on my blog on shaping the larger kind of conversation across the internet uh for where people even get this idea. Um so I've noticed this when I do Gemini Deep Research where it goes and looks across the web for topics I frequently see my blog in the list of sources consulted. Uh which gives me hope that maybe I can influence the search engines the sorry the AI tools that gather and come up with things so that when you have an exec who's typing "should I get rid of my tech writers," your post or my posts other posts are going to be like factored into AI's response that says "no that's a bad idea," you know. This is this is why I at some point I I pushed back on the hype of AI because I didn't want to give this wrong impression to upper leaders that uh that everything I was doing could be replaced by AI.

Um there was this little tagline that we were putting on our on our changelists that's like "AI used? Yes." Like no I'm not putting that tagline anymore on my my changelists. I don't want to I don't want to give the wrong idea because that's really that's really like our biggest danger is like some senior leader gets a whiff who doesn't understand tech writing gets a whiff of this idea that "oh tech writing that's now automated. You got you've got a code wiki? Ah you don't need documentation anymore." Uh doc theater yeah. Yeah. Um that's our biggest risk because gosh when you as I mentioned earlier when you start to really try to automate an actual process that a tech writer does it's extremely difficult and you find that almost nobody's doing it and you can only get like part of it. So um anyway.

**Fabrizio:** You know I I'm seeing more and more technical writers blogging these days and it's really encouraging. And I think this is way better than SEO. I mean we are planting the seeds in the future LLM versions of you know what they should be doing and and and telling uh stakeholders about. So yeah get get your words out there get your voice out there because that's the context that is gonna you know upon which they're gonna train the models in the future you know.

**Tom:** And hey here's another great reason to start blogging. If you're having AI do more writing at work where and you feel like my writing skills are becoming rusty and you want to like let your humanity sort of uh free you you should blog. Um there's a I'll post a link to the CT's blog ring that has a good list of other blogs. And yeah you can get some ideas super easy to get a blog out and and uh yeah I think tech writers might realize that blogging is actually a lot harder than it than it looks. Um you can't just like throw a post out in 10 minutes and and have everybody in the world read it. Like takes a lot of time but it's also really rewarding. And I get to connect with people like you. I mean through your blog I know that you exist and you know that I exist.

**Fabrizio:** Well I think it's really helping us stay sane you know.

**Tom:** For sure. All right well hey we're at the hour. Um any last topics we want to cover or did we do a good job in in covering predictions?

**Fabrizio:** Yeah yeah I would say I really looking forward to have like uh more hosts in the future. I think it's it's uh you know it's going great so far. Uh especially if they have to tell like the way they're using AI at work that would be like very inspiring. So uh you know if you are listening to this and would like to participate you know just ping us.

**Tom:** For sure. We have we have some hosts lined up in in our next ones we've been alternating between hosts or having a guest and not a guest and seeing how that works. So yeah give us feedback. What do you like? What do you want to hear about? Do you want to participate? We'd love to to hear from you. So thanks again for listening and again uh if you want to read more of Fabry's blog passo.uno. My blog is idratherbewriting.com. And uh we will publish all the links to resources mentioned in the show notes. So thanks.

**Fabrizio:** Thank you.






