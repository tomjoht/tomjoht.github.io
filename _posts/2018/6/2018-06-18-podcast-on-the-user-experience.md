---
title: "Evaluating the user experience of documentation -- Podcast with Bob Watson"
categories:
- user-experience
- podcasts
keywords: usability, twilio, user experience
description: "This week I chatted with <a href='https://www.linkedin.com/in/docsbydesign/'>Bob Watson</a>, an assistant professor of tech comm at <a href='https://engineering.mercer.edu/academics/undergraduate/technical-communication/'>Mercer University</a>, about how to evaluate the user experience of documentation. The idea of doing a podcast came up during a comment thread on a previous post about <a href='https://idratherbewriting.com/simplifying-complexity/reconstructing-the-absent-user.html'>reconstructing the absent user.</a> We had a long exchange in the comment threads and thought it would be good to have a podcast about the topic."
bitlink: http://bit.ly/evaluatinguserexperiencebobwatson
image: idratherbewritinglogo.png
podcast_link: https://www.podtrac.com/pts/redirect.mp3/s3.us-west-1.wasabisys.com/idbwmedia.com/podcasts/evaluatinguserexperience.mp3
podcast_file_size: 42.1 MB
podcast_duration: "58:19"
podcast_length: 42076307
---

* TOC
{:toc}

You can listen to the podcast here:

{% include audio.html %}

Here are a few questions we cover during the podcast:

* Should tech writers do user testing and research, or is this product team’s job in designing the product?
* Can’t we just leverage marketing personas for the user research we need?
* How can looking at the market and product angles help clarify user needs and behaviors?
* What kind of knowledge can we leverage from universal design patterns about how users consume docs?
* How do we avoid hasty generalizations from a user sample that's too small?
* Is it feasible for tech writers to actually do user testing on top of all of their other duties?
* How can you make feedback forms on docs more likely to get responses from users?
* If you collect feedback at major milestones that users complete, how do you avoid just collecting responses from successful users?
* How does Twilio successfully collect info from their users?
* How can you successfully gather metrics that show user success or failure on tasks?
* How can you make your feedback surveys specific to the data so that you get better responses?

For more information about Bob Watson, see his site, [Docs by Design](http://docsbydesign.com/).

{% include ads.html %}
