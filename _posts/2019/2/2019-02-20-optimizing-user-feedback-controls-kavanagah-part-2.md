---
title: "Optimizing documentation feedback forms -- Part II"
categories:
- academics-and-practitioners
- user-centered-documentation
keywords:
bitlink: http://bit.ly/
description: ""
published: false
---

{{site.data.alerts.note}}
This is part II of the essay. See ["Optimizing documentation feedback forms -- Part I](/optimizing-user-feedback-controls-kavanagah-part-1/) first.
{{site.data.alerts.end}}

## 4. Explaining the Tables of Results

The initial part of this section explains how to read the tables of quantitative data.  

Each number in the Sample Text column ([1] &mdash; [20]) represents an online help system for a project management software. For example, '[2]' is the online help system that accompanies the Monday.com software product. Refer to the Appendix to identify the project management software in each case. The final column, Total & % of Sample Texts, provides the following information:  

*   Total number of sample texts in which the relevant element is applied.
*   Percentage of the sample texts in which the relevant element is applied.

For both content and information design, I recorded the presence of specific elements across a range of categories. In the following sections I explain those categories and elements.

### 4.1. Information Design Categories of Analysis

The **Initial Feedback** category represents the initial method of feedback that is displayed to the user. Figure 1 shows the feedback option that a user encounters at the foot of a help topic for the Paymo [13] product.

<p id="gdcalert2" ><span style="color: red; font-weight: bold">>>>>>  gd2md-html alert: inline image link here (to images/10084363-TW5221-FinalReport1.png). Store image on your image server and adjust path/filename if necessary. </span><br>(<a href="#">Back to top</a>)(<a href="#gdcalert3">Next alert</a>)<br><span style="color: red; font-weight: bold">>>>>> </span></p>

![alt_text](/images/kavanagh-00.png "image_tooltip")
_Figure 1 - Example of an initial feedback option_

**Design Elements** are the various design strategies that are employed to attract the user's eye to the feedback option. 'Contrasting colour' refers to the use of colours that are not applied in the surrounding instructional content, thus highlighting the feedback options. Figure 2 displays the use of contrasting colour (green and red) by Everhour [16]. 'Alignment' refers to the use of a different alignment to what is applied to the rest of the topic. This strategy is also employed in Figure 2 where the feedback feature is centred.

<p id="gdcalert3" ><span style="color: red; font-weight: bold">>>>>>  gd2md-html alert: inline image link here (to images/10084363-TW5221-FinalReport2.png). Store image on your image server and adjust path/filename if necessary. </span><br>(<a href="#">Back to top</a>)(<a href="#gdcalert4">Next alert</a>)<br><span style="color: red; font-weight: bold">>>>>> </span></p>

![alt_text](/images/kavanagh-03.png "image_tooltip")
_Figure 2 - Use of colour and alignment in a feedback feature_

The **Feedback Location** records the location of the feedback feature on a typical topic screen in each of the sample texts.

### 4.2. Content Categories of Analysis

The **Initial Question** captures the initial prompt to users to provide feedback.

The **Acknowledgement** category reveals whether the sample texts acknowledge a positive or negative response by the user. I did not include instances where a button or emoticon retains a clicked state. I only recorded an acknowledgement where a textual message is displayed. Figure 3 displays an acknowledgement by Favro [15] when a user selects a negative reaction to the help topic. This category also indicates whether sample texts indicate, by way of the wording of a question or an acknowledgement message, that feedback is used to improve product documentation.

<p id="gdcalert4" ><span style="color: red; font-weight: bold">>>>>>  gd2md-html alert: inline image link here (to images/10084363-TW5221-FinalReport3.png). Store image on your image server and adjust path/filename if necessary. </span><br>(<a href="#">Back to top</a>)(<a href="#gdcalert5">Next alert</a>)<br><span style="color: red; font-weight: bold">>>>>> </span></p>

![alt_text](/images/kavanagh-04.png "image_tooltip")
_Figure 3 - Acknowledgement of a negative reaction by a user_

The **Further Feedback** category indicates whether the user can provide additional feedback after an initial response. Figure 4 shows how Zoho Sprints [10] prompts the user to submit their email address after the user has provided initial feedback. A third element identifies those online help systems where users are directed to customer support after providing an initial negative response.

![alt_text](/images/kavanagh-05.png "image_tooltip")
_Figure 4 - User's email is requested for feedback follow-up_

The **Subsequent Feedback Methods** category captures the methods by which online help systems acquire further feedback from users after they respond to the initial question. For example, Widen Collective [11] display the following options (Figure 5) when a user selects 'No' in response to the opening question 'Did you find it helpful?'

![alt_text](/images/kavanagh-06.png "image_tooltip")
_Figure 5 - Acquiring further feedback from the user_

The final category of **Global Approval** lists the online help systems that display how many users have responded positively to the help topic. Figure 6 is an example from Insightly [7].

![alt_text](/images/kavanagh-07.png "image_tooltip")
_Figure 6 - Displaying user rating of a help topic_

## 5. Information Design Categories: Results, Summary and Discussion

Table 1 displays the results of the information design analysis.

<table>
  <tr>
   <td>Category 
   </td>
   <td>Element 
   </td>
   <td>Source 
   </td>
   <td>Total & % of Sample Texts 
   </td>
  </tr>
  <tr>
   <td>Initial Feedback 
   </td>
   <td>Yes/No [clickable text] 
   </td>
   <td>[1], [11], [12], [17] 
   </td>
   <td>4 &mdash; 20% 
   </td>
  </tr>
  <tr>
   <td> 
   </td>
   <td>Yes/No [buttons] 
   </td>
   <td>[5], [6]*, [8], [14], [19], [20] 
   </td>
   <td>6 – 30% 
   </td>
  </tr>
  <tr>
   <td> 
   </td>
   <td>Clickable thumbs up/down 
   </td>
   <td>[2], [3], [7], [10] 
   </td>
   <td>4 &mdash; 20% 
   </td>
  </tr>
  <tr>
   <td> 
   </td>
   <td>Rating system (Likert Scale) 
   </td>
   <td>[4] 
   </td>
   <td>1 &mdash; 5% 
   </td>
  </tr>
  <tr>
   <td> 
   </td>
   <td>Clickable emoticons (happy, neutral, sad) 
   </td>
   <td>[9], [13], [15] 
   </td>
   <td>3 – 15% 
   </td>
  </tr>
  <tr>
   <td> 
   </td>
   <td>Submit comment 
   </td>
   <td>[6]* 
   </td>
   <td>1 &mdash; 5% 
   </td>
  </tr>
  <tr>
   <td> 
   </td>
   <td>Clickable tick ('✓') and Cross ('✗') marks 
   </td>
   <td>[16] 
   </td>
   <td>1 &mdash; 5% 
   </td>
  </tr>
  <tr>
   <td> 
   </td>
   <td>Clickable 'Like' icon 
   </td>
   <td>[18] 
   </td>
   <td>1 &mdash; 5% 
   </td>
  </tr>
  <tr>
   <td> 
   </td>
   <td> 
   </td>
   <td> 
   </td>
   <td> 
   </td>
  </tr>
  <tr>
   <td>Design Elements 
   </td>
   <td>Contrasting colour 
   </td>
   <td>[2], [3], [5], [9], [13], [14], [15], [16], [20] 
   </td>
   <td>9 – 45% 
   </td>
  </tr>
  <tr>
   <td> 
   </td>
   <td>Background colour/shading 
   </td>
   <td>[1], [9], [10], [13], [15], [16], [18] 
   </td>
   <td>7 – 35% 
   </td>
  </tr>
  <tr>
   <td> 
   </td>
   <td>Feedback heading/larger font 
   </td>
   <td>[2], [3], [5], [10], [16] 
   </td>
   <td>5 &mdash; 25% 
   </td>
  </tr>
  <tr>
   <td> 
   </td>
   <td>Spacing 
   </td>
   <td>[1], [2], [3], [4], [5], [6], [7], [8], [10], [13], [14], [15], [16], [19], [20] 
   </td>
   <td>15 &mdash; 75% 
   </td>
  </tr>
  <tr>
   <td> 
   </td>
   <td>Bordering 
   </td>
   <td>[1], [5], [11], [19] 
   </td>
   <td>4 – 20% 
   </td>
  </tr>
  <tr>
   <td> 
   </td>
   <td>Alignment 
   </td>
   <td>[1], [2], [4], [9], [13], [14], [15], [16] 
   </td>
   <td>9 &mdash; 40% 
   </td>
  </tr>
  <tr>
   <td> 
   </td>
   <td> 
   </td>
   <td> 
   </td>
   <td> 
   </td>
  </tr>
  <tr>
   <td>Feedback Location 
   </td>
   <td>Foot of topic 
   </td>
   <td>[1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [12], [13], [14], [15], [16], [17], [19], [20] 
   </td>
   <td>18 &mdash; 90% 
   </td>
  </tr>
  <tr>
   <td> 
   </td>
   <td>Topic heading 
   </td>
   <td>[18] 
   </td>
   <td>1 &mdash; 5% 
   </td>
  </tr>
  <tr>
   <td> 
   </td>
   <td>Sidebar 
   </td>
   <td>[11] 
   </td>
   <td>1 &mdash; 5% 
   </td>
  </tr>
</table>
_Table 1 - Information Design Categories and Results_


### 5.1 'Initial feedback' category

Four design formats stand out among the sample texts as the most popular methods of prompting initial feedback from the user:  

*   Yes/No [clickable text] - 20%
*   Yes/No [buttons] - 30%
*   Clickable thumbs up/down - 20%
*   Clickable emoticons (happy, neutral, sad) - 15%

Just one sample text &mdash; Confluence [6] - provides more than one initial method of feedback: Yes/No buttons and comment submission. By ensuring that all user feedback includes positive or negative responses, all the other texts align with the recommendations of Hackos (1994) and Novick and Ward (2006) that baseline quantifiable information about customer satisfaction is acquired.

The feedback option is something actionable in the online help system. Unlike searching or navigating, the user is submitting something to the software organisation &mdash; as they would a payment or account registration. The action to submit feedback therefore requires a more visually arresting interface element than clickable text. This approach aligns with Brink _et al_'s (2002) guideline of contrast and Kimball and Hawkins (2008) call for clear visual cues.  All the initial feedback design formats meet this requirement, except the 20% that apply the Yes/No [clickable text] format.

### 5.2. 'Design Elements' Category

In terms of design elements, spacing is the most common method by which the designers of online help draw attention to the feedback feature. Fifteen texts (75%) include this strategy. Given the limited amount of page estate occupied by a feedback option, and that it is easily encapsulated by an observable band of white space, this result is to be expected.  Only 5 (25%) of the sample texts employ a heading or larger font to highlight a feedback option. Kimball and Hawkins (2008) emphasis on the importance of headings in information design is evidently not shared by most of the sampled online help designers.

### 5.3. 'Feedback Location' Category

Ninety per cent of the sampled texts located their feedback feature at the foot of the topic. While this does indicate a level of predictability for users of online help who want to provide feedback, it does not necessarily accord with Brink _et al_'s (2002) principle of navigation, i.e. that the feedback feature is easily found. In many cases, the sample texts contained topics that were very long with many sections dealing with specific user issues. A high probability exists that a user would simply read the relevant section and exit the topic without noticing the feedback area. Widen Collective's [11] sidebar location also fails to avoid this problem as the sidebar is not fixed and disappears as the user scrolls down the screen. Apart from navigation, the location in these instances also fail the principle of ease-of-use and efficiency, as highlighted by Nichols _et al_ (2003) and Kantner _et al_ (2002). Requiring users to scroll down a very long topic is poor usability. The single sample text to emerge well from this category of analysis is Brightpod [18]. Although it acquires the bare minimum of user feedback information, and is otherwise poorly highlighted by its design, the feedback feature is in the topic heading (circled in Figure 7 below) where it will be encountered by most or all visitors to the topic.

![alt_text](/images/kavanagh-08.png "image_tooltip")
_Figure 7 - Feedback feature in the topic heading_

## 6. Content Categories: Results, Summary and Discussion

Table 2 displays the results of the content analysis.

<table>
  <tr>
   <td>Category 
   </td>
   <td>Element 
   </td>
   <td>Source 
   </td>
   <td>Total - % of Sample Texts 
   </td>
  </tr>
  <tr>
   <td>Initial Question 
   </td>
   <td>'Was this article helpful?' 
   </td>
   <td>[1], [2], [3], [7], [8], [16] 
   </td>
   <td>6 &mdash; 30% 
   </td>
  </tr>
  <tr>
   <td> 
   </td>
   <td>'How helpful was this article?' [1-10 Likert Scale} 
   </td>
   <td>[4] 
   </td>
   <td>1 &mdash; 5% 
   </td>
  </tr>
  <tr>
   <td> 
   </td>
   <td>'Did this article help you?' 
   </td>
   <td>[5] 
   </td>
   <td>1 &mdash; 5% 
   </td>
  </tr>
  <tr>
   <td> 
   </td>
   <td>'Was this helpful?' 
   </td>
   <td>[6] 
   </td>
   <td>1 &mdash; 5% 
   </td>
  </tr>
  <tr>
   <td> 
   </td>
   <td>'Did this answer your question?' 
   </td>
   <td>[9], [13], [15], [19] 
   </td>
   <td> 
   </td>
  </tr>
  <tr>
   <td> 
   </td>
   <td>'Helpful?' 
   </td>
   <td>[10] 
   </td>
   <td>1 &mdash; 5% 
   </td>
  </tr>
  <tr>
   <td> 
   </td>
   <td>'Did you find it helpful?' 
   </td>
   <td>[11], [12] 
   </td>
   <td> 
   </td>
  </tr>
  <tr>
   <td> 
   </td>
   <td>'Have we made a good job with this post?' 
   </td>
   <td>[14] 
   </td>
   <td>1 &mdash; 5% 
   </td>
  </tr>
  <tr>
   <td> 
   </td>
   <td>'Was this answer helpful?' 
   </td>
   <td>[17] 
   </td>
   <td>1 &mdash; 5% 
   </td>
  </tr>
  <tr>
   <td> 
   </td>
   <td>'Did this article answer your question?' 
   </td>
   <td>[20] 
   </td>
   <td>1 &mdash; 5% 
   </td>
  </tr>
  <tr>
   <td> 
   </td>
   <td> 
   </td>
   <td> 
   </td>
   <td> 
   </td>
  </tr>
  <tr>
   <td> Acknowledgement 
   </td>
   <td>Message in response to positive response 
   </td>
   <td>[1], [3], [4], [5], [8], [11], [12], [16], [20] 
   </td>
   <td>9 &mdash; 45% 
   </td>
  </tr>
  <tr>
   <td> 
   </td>
   <td>Message in response to negative response 
   </td>
   <td>[1], [3], [4], [5], [8], [11], [12], [15], [16], [19], [20] 
   </td>
   <td>11 &mdash; 55% 
   </td>
  </tr>
  <tr>
   <td> 
   </td>
   <td>Indication that feedback is used to improve documentation 
   </td>
   <td>[3], [4], [8], [11], [12], [16], [20] 
   </td>
   <td>7 &mdash; 35% 
   </td>
  </tr>
  <tr>
   <td> 
   </td>
   <td> 
   </td>
   <td> 
   </td>
   <td> 
   </td>
  </tr>
  <tr>
   <td>Further Feedback 
   </td>
   <td>Opportunity to provide further feedback after initial response 
   </td>
   <td>[3], [4], [5], [6], [8], [10], [11], [12], [16], [20] 
   </td>
   <td>10 &mdash; 50% 
   </td>
  </tr>
  <tr>
   <td> 
   </td>
   <td>No option to provide further feedback 
   </td>
   <td>[2], [7], [14], [17], [18] 
   </td>
   <td>5 &mdash; 25% 
   </td>
  </tr>
  <tr>
   <td> 
   </td>
   <td>Redirected to support after initial negative feedback 
   </td>
   <td>[1], [9], [13], [15], [19] 
   </td>
   <td>5 &mdash; 25% 
   </td>
  </tr>
  <tr>
   <td> 
   </td>
   <td> 
   </td>
   <td> 
   </td>
   <td> 
   </td>
  </tr>
  <tr>
   <td>Subsequent Feedback Methods 
   </td>
   <td>Submit Comment 
   </td>
   <td>[3], [4], [5], [10], [11], [12], [16], [20] 
   </td>
   <td>8 &mdash; 40% 
   </td>
  </tr>
  <tr>
   <td> 
   </td>
   <td>Question &mdash; multiple choice 
   </td>
   <td>[11], [12] 
   </td>
   <td>2 &mdash; 10% 
   </td>
  </tr>
  <tr>
   <td> 
   </td>
   <td>Question &mdash; single choice 
   </td>
   <td>[4], [6] 
   </td>
   <td>2 &mdash; 10% 
   </td>
  </tr>
  <tr>
   <td> 
   </td>
   <td>Submit email address 
   </td>
   <td>[3], [4], [5], [8], [10], [11], [12] 
   </td>
   <td>7 &mdash; 35% 
   </td>
  </tr>
  <tr>
   <td> 
   </td>
   <td> 
   </td>
   <td> 
   </td>
   <td> 
   </td>
  </tr>
  <tr>
   <td>Global Approval 
   </td>
   <td>e.g. number of Likes or '3 of 8 found this helpful' 
   </td>
   <td>[2], [7], [10], [14], [17], [18] 
   </td>
   <td>6 &mdash; 30% 
   </td>
  </tr>
</table>
_Table 2 - Content Categories and Results_

### 6.1 'Initial Question' Category

In all cases, the initial question put to users generates a positive/negative response, or a graded response in the case of Resource Guru [4] (displayed in Figure 8 below), thereby compiling meaningful and quantifiable answers as recommended by Hackos (1994).

![alt_text](/images/kavanagh-00.png "image_tooltip")
_Figure 8 - Likert scale for initial feedback question_

However, clarity is a best practice recommended by Kantner _et al_ (2002) and Markel (2012) and this is not displayed in all the initial questions. For example, several of the questions do not explicitly state that the question is about the preceding topic. Questions such as the following are vague, especially for users for whom English is not their first language, or users who have engaged with support on the same screen through a chat option or link:

*   'Helpful?' [10]
*   'Did you find it helpful?' [11], [12]

Other questions pose a question as though all users have visited the topic with a specific question in mind. Users who have visited the page to learn how to use the product or to explore a new feature will not be engaged by questions such as the following:

*   'Did this answer your question?' [9], [13], [15]
*   'Was this answer helpful?' [17]
*   'Did this article answer your question?' [20]

And finally, the question posed by TimeCamp [14], 'Have we made a good job with this post?', reads like the user is being asked to hold the author personally accountable rather than react freely and without inhibition to the topic's content.

### 6.2. 'Acknowledgement' Category

Acknowledgement is key to user motivation. When users take part in usability tests or focus groups, they are warmly thanked in advance and after the process. The same should apply online. However, over half (55%) of the sample texts do not acknowledge a positive response to the initial feedback question, and 50% do not acknowledge a negative response. In these scenarios, no effort is made to ensure that the user continues to provide feedback as they engage with different topics. Furthermore, even fewer of the sample texts (35%) indicate that feedback is used to improve the documentation. As noted by Maalej _et al_ (2009), overcoming considerable user reluctance is a key challenge in securing feedback. Without clear communication of the purpose of the activity, users are not sufficiently motivated to repeatedly engage with a feedback feature.  In accordance with Markel's (2012) writing guidelines, a feedback feature should engender in the user the belief that their feedback will be acted upon.

### 6.3. 'Further Feedback' Category

Markel also wrote that content should help users to complete a task. In the case of providing feedback, the task is to provide feedback that accurately conveys their experience of the relevant help topic. Fifty per cent of the sample texts do not provide users with the opportunity to provide further feedback. In other words, users are limited to expressing a positive or negative rating of the topic. As Novick and Ward's (2006) research reveals, user frustrations with online help are varied, and the nature of those frustrations cannot be expressed through an emoticon or by clicking a Yes/No button. However, 20% of the online help systems have no option to submit further feedback but redirect the user to a customer support service. For example, this strategy is applied by Paymo [13] (see Figure 9). It may be the case that the Paymo support team record further details about the user's experience of the help topic. They might subsequently apply this information to improve the topic as authors of the online help or forward it to a technical communication team. This can only be known through further research.

![alt_text](/images/kavanagh-10.png "image_tooltip")
_Figure 9  - User redirected to support after providing negative feedback_

### 6.4. 'Subsequent Feedback Methods' Category

Applied by 40% of sample texts, comment submission is the most common method by which feedback is subsequently acquired from users. While this allows the user to capture in detail their experience of the help topic and is a source of good qualitative information for technical writers, it does not allow for quantitative measurement of how the online help system is performing. Four help systems (20%) display a question with fixed answer options that represent issues that the user may have encountered. This approach tallies with Novick and Ward's (2006) recommendation that users are provided with answer options that generate quantifiable data. However, two of the four sample texts ([4] and [6]) provide radio button (i.e. single-choice) answer options, as displayed in Figure 10 below (taken from Confluence [6]).  This question type limits the ability of the user to accurately report their experience in a quantifiable format. This is less of an issue where a multiple-choice question is posed ([11] and [12]) although answer options still need to capture a user's typical frustrations.

![alt_text](/images/kavanagh-11.png "image_tooltip")
_Figure 10 - Single choice question in a feedback feature_

### 6.5. 'Global Approval' Category

A significant percentage of sample texts (35%) display a count of how many users have responded positively to the help topic. When analysed in terms of Markel's (2012) writing considerations, the displayed ratings do not help users to understand the feedback or cause them to think that their feedback will be acted upon. Indeed, a user might conclude that the purpose of the feedback process is to identify the most popular help topics rather than to improve the content.  

More broadly, all the sample texts consisted of instructional, task-based topics &mdash; not user workarounds, suggested applications or handy tips &mdash; and must therefore accurately explain a process in a style consistent with all the other task-based topics in the online help. In other words, the user either needs to read the topic to complete a process or they do not: recommendations of the topic by other users are irrelevant.

In the following section, I present my conclusions and recommendations for further research.

## 7. Conclusions & Recommendations

Aristotle's three principles of rhetoric (Kimball and Hawkins 2008) - ethos, pathos and logos &mdash; are an appropriate method by which we can measure the application of principles of information design and content writing in the feedback features of online help systems.  

In terms of pathos, I suggest that the online help systems largely succeed in clearing demarcating their feedback features using white space, contrasting colours and other design elements. For the most part, users are enticed to submit feedback with well-designed buttons and clickable icons that attract the eye.  

However, in terms of ethos and logos, a large majority of the sample texts fail to deliver. A lack of acknowledgement of users' feedback and even less communication as to how it will be used to improve documentation mean that users will not believe that their feedback is valued and will not understand their place in a process that is ultimately for their benefit, i.e. the continuous improvement of the online help.

In addition, unstructured and poorly written content means that in most cases, users are responding to vague questions that will provoke vague answers which are unquantifiable.

Based largely on content failings therefore, but also design failings such as the feedback location and lack of headings, I submit that the research hypothesis is correct and best practice principles of information design and content writing are not applied to user feedback options of online help systems for project management software tools.

It appears that online help systems are thoughtlessly mimicking the interactive elements of Web 2.0 websites where the single-click 'liking' or recommending of articles is commonplace. More thought needs to go into how user interaction can be harnessed to efficiently acquire useful and quantifiable feedback. For further research, I recommend a project that develops and tests a working model of a feedback system that achieved these goals.   

Finally, an obvious limitation of this project is the absence of data on the feedback that the sample texts acquire. Research into how different feedback models fare, tackling issues such as how much feedback is captured, the quality of that feedback and what technical writers do with it, is a natural progression from this report.

## References

Abel, S. (2011) The Future of technical communication is socially enabled: Understanding the Help 2.0 revolution. _Intercom_, 58(4), pp.6-10. 

Andersen, R. (2014) Rhetorical work in the age of content management: Implications for the field of technical communication. _Journal of Business and Technical Communication_, 28(2), pp.115-157. 

Brinck, T., Gergle, D. and Wood, S.D. (2002) _Usability for the Web: Designing Web Sites That Work_, San Francisco: Morgan Kaufmann Publishers. 

Capterra (2018) _Project Management Software_, available: [https://www.capterra.com/project-management-software/?utf8=%E2%9C%93&users=&sort_options=Highest+Rated](https://www.capterra.com/project-management-software/?utf8=%E2%9C%93&users=&sort_options=Highest+Rated)<span style="text-decoration:underline;"> [accessed </span>7 Nov 2018]. 

Gurak, L.J. and Hocks, M.E. (2009) _The Technical Communication Handbook_, New York: Pearson Longman. 

Hackos, J.T. (1994) _Managing your documentation projects_. J. Wiley. 

Kantner, L., Shroyer, R. and Rosenbaum, S. (2002) Structured heuristic evaluation of online documentation. In _Professional Communication Conference, 2002. IPCC 2002. Proceedings. IEEE International_ (pp. 331-342). IEEE. 

Kimball, M.A. and Hawkins, A.R. (2008) _Document design: A guide for technical communicators_. Boston, Massachusetts: Bedford/St. Martin's. 

Kunz, L. (2010) May. Managing documentation projects in a collaborative world. In _Proceedings for the Society for Technical Communications 2010 Conference_. 

Maalej, W., Happel, H.J. and Rashid, A. (2009) October. When users become collaborators: towards continuous and context-aware user input. In _Proceedings of the 24th ACM SIGPLAN conference companion on Object oriented programming systems languages and applications_ (pp. 981-990). ACM. 

Markel, M. (2012) _Technical Communication_, 10<sup>th</sup> ed., Boston: Bedford/St. Martin's. 

Nichols, D.M., McKay, D. and Twidale, M.B. (2003) July. Participatory Usability: supporting proactive users. In _Proceedings of the 4th Annual Conference of the ACM Special Interest Group on Computer-Human Interaction_ (pp. 63-68). ACM. 

Novick, D.G. and Ward, K. (2006) October. What users say they want in documentation. In _Proceedings of the 24th annual ACM international conference on Design of Communication_ (pp. 84-91). ACM. 

## Appendix &mdash; Texts Considered for Inclusion

The online help systems for the following project management software products were considered for inclusion. The systems were accessed on 18/11/2018.

<table>
  <tr>
   <td>Product 
   </td>
   <td>Included? 
   </td>
   <td>Why Excluded? 
   </td>
   <td>Source No. 
   </td>
  </tr>
  <tr>
   <td>Asana 
   </td>
   <td><strong>Yes </strong>
   </td>
   <td> 
   </td>
   <td><strong>1</strong> 
   </td>
  </tr>
  <tr>
   <td>Mavenlink 
   </td>
   <td>No 
   </td>
   <td>Contact Support - ticket/chat 
   </td>
   <td> 
   </td>
  </tr>
  <tr>
   <td>Accelo 
   </td>
   <td>No 
   </td>
   <td>No feedback 
   </td>
   <td> 
   </td>
  </tr>
  <tr>
   <td>Monday.com 
   </td>
   <td><strong>Yes</strong> 
   </td>
   <td> 
   </td>
   <td><strong>2</strong> 
   </td>
  </tr>
  <tr>
   <td>Zoho Projects 
   </td>
   <td>No 
   </td>
   <td>Contact Support - email 
   </td>
   <td> 
   </td>
  </tr>
  <tr>
   <td>ADEACA - Project Business Automation 
   </td>
   <td>No 
   </td>
   <td>Not accessed 
   </td>
   <td> 
   </td>
  </tr>
  <tr>
   <td>Workfront 
   </td>
   <td>No 
   </td>
   <td>Login required 
   </td>
   <td> 
   </td>
  </tr>
  <tr>
   <td>Daylite 
   </td>
   <td><strong>Yes</strong> 
   </td>
   <td> 
   </td>
   <td><strong>3</strong> 
   </td>
  </tr>
  <tr>
   <td>Resource Guru 
   </td>
   <td><strong>Yes</strong> 
   </td>
   <td> 
   </td>
   <td><strong>4</strong> 
   </td>
  </tr>
  <tr>
   <td>KeyedIn Projects 
   </td>
   <td>No 
   </td>
   <td>Not accessed 
   </td>
   <td> 
   </td>
  </tr>
  <tr>
   <td>Scoro 
   </td>
   <td>No 
   </td>
   <td> 
   </td>
   <td><strong>5</strong> 
   </td>
  </tr>
  <tr>
   <td>Teamwork Projects 
   </td>
   <td>No 
   </td>
   <td>Contact Support - form 
   </td>
   <td> 
   </td>
  </tr>
  <tr>
   <td>Redbooth 
   </td>
   <td>No 
   </td>
   <td>Login required 
   </td>
   <td> 
   </td>
  </tr>
  <tr>
   <td>SmartDraw 
   </td>
   <td>No 
   </td>
   <td>No feedback 
   </td>
   <td> 
   </td>
  </tr>
  <tr>
   <td>Confluence 
   </td>
   <td><strong>Yes</strong>  
   </td>
   <td> 
   </td>
   <td><strong>6</strong> 
   </td>
  </tr>
  <tr>
   <td>Proggio 
   </td>
   <td>No 
   </td>
   <td>No feedback 
   </td>
   <td> 
   </td>
  </tr>
  <tr>
   <td>Easy Projects 
   </td>
   <td>No 
   </td>
   <td>Login required 
   </td>
   <td> 
   </td>
  </tr>
  <tr>
   <td>Hygger 
   </td>
   <td>No 
   </td>
   <td>Login required 
   </td>
   <td> 
   </td>
  </tr>
  <tr>
   <td>Standuply 
   </td>
   <td>No 
   </td>
   <td>Login required 
   </td>
   <td> 
   </td>
  </tr>
  <tr>
   <td>Insightly 
   </td>
   <td><strong>Yes</strong> 
   </td>
   <td> 
   </td>
   <td><strong>7</strong> 
   </td>
  </tr>
  <tr>
   <td>edison365 Projects 
   </td>
   <td>No 
   </td>
   <td>Not accessed 
   </td>
   <td> 
   </td>
  </tr>
  <tr>
   <td>Forecast 
   </td>
   <td><strong>Yes</strong>  
   </td>
   <td> 
   </td>
   <td><strong>8</strong> 
   </td>
  </tr>
  <tr>
   <td>ActiveCollab 
   </td>
   <td>No 
   </td>
   <td>Contact support - email 
   </td>
   <td> 
   </td>
  </tr>
  <tr>
   <td>TeamHeadquarters 
   </td>
   <td>No 
   </td>
   <td>No feedback 
   </td>
   <td> 
   </td>
  </tr>
  <tr>
   <td>Pipefy 
   </td>
   <td><strong>Yes</strong>  
   </td>
   <td> 
   </td>
   <td><strong>9</strong> 
   </td>
  </tr>
  <tr>
   <td>VivifyScrum 
   </td>
   <td>No 
   </td>
   <td>Contact support - chat 
   </td>
   <td> 
   </td>
  </tr>
  <tr>
   <td>Zoho Sprints 
   </td>
   <td><strong>Yes</strong> 
   </td>
   <td> 
   </td>
   <td><strong>10</strong> 
   </td>
  </tr>
  <tr>
   <td>MangoApps 
   </td>
   <td>No 
   </td>
   <td>No feedback 
   </td>
   <td> 
   </td>
  </tr>
  <tr>
   <td>PROJECT in a box 
   </td>
   <td>No 
   </td>
   <td>No feedback 
   </td>
   <td> 
   </td>
  </tr>
  <tr>
   <td>Widen Collective 
   </td>
   <td><strong>Yes</strong> 
   </td>
   <td> 
   </td>
   <td><strong>11</strong> 
   </td>
  </tr>
  <tr>
   <td>Avaza 
   </td>
   <td>No 
   </td>
   <td>Contact support email/chat 
   </td>
   <td> 
   </td>
  </tr>
  <tr>
   <td>MeisterTask 
   </td>
   <td>No 
   </td>
   <td>Contact support - form 
   </td>
   <td> 
   </td>
  </tr>
  <tr>
   <td>Twproject 
   </td>
   <td>No 
   </td>
   <td>Contact support - form 
   </td>
   <td> 
   </td>
  </tr>
  <tr>
   <td>ServiceDesk Plus 
   </td>
   <td>No 
   </td>
   <td>No feedback 
   </td>
   <td> 
   </td>
  </tr>
  <tr>
   <td>todo.vu 
   </td>
   <td>No 
   </td>
   <td>Contact support - email 
   </td>
   <td> 
   </td>
  </tr>
  <tr>
   <td>Samepage 
   </td>
   <td>No 
   </td>
   <td>Contact support - form 
   </td>
   <td> 
   </td>
  </tr>
  <tr>
   <td>Wrike 
   </td>
   <td>No 
   </td>
   <td>Login required 
   </td>
   <td> 
   </td>
  </tr>
  <tr>
   <td>Freshdesk 
   </td>
   <td><strong>Yes</strong> 
   </td>
   <td> 
   </td>
   <td><strong>12</strong> 
   </td>
  </tr>
  <tr>
   <td>airfocus 
   </td>
   <td>No 
   </td>
   <td>Not accessed 
   </td>
   <td> 
   </td>
  </tr>
  <tr>
   <td>FOURSITE 
   </td>
   <td>No 
   </td>
   <td>Not accessed 
   </td>
   <td> 
   </td>
  </tr>
  <tr>
   <td>Wimi 
   </td>
   <td>No 
   </td>
   <td>Community forum 
   </td>
   <td> 
   </td>
  </tr>
  <tr>
   <td>Paymo 
   </td>
   <td><strong>Yes</strong> 
   </td>
   <td> 
   </td>
   <td><strong>13</strong> 
   </td>
  </tr>
  <tr>
   <td>Synapcus 
   </td>
   <td>No 
   </td>
   <td>Not accessed 
   </td>
   <td> 
   </td>
  </tr>
  <tr>
   <td>HarmonyPSA 
   </td>
   <td>No 
   </td>
   <td>Not accessed 
   </td>
   <td> 
   </td>
  </tr>
  <tr>
   <td>Agile CRM 
   </td>
   <td>No 
   </td>
   <td>Contact support - email/chat 
   </td>
   <td> 
   </td>
  </tr>
  <tr>
   <td>The Critical Path 
   </td>
   <td>No 
   </td>
   <td>Not accessed 
   </td>
   <td> 
   </td>
  </tr>
  <tr>
   <td>Quire 
   </td>
   <td>No 
   </td>
   <td>Forum comments 
   </td>
   <td> 
   </td>
  </tr>
  <tr>
   <td>Basecamp 
   </td>
   <td>No 
   </td>
   <td>Contact support - form 
   </td>
   <td> 
   </td>
  </tr>
  <tr>
   <td>Microsoft PPM 
   </td>
   <td>No 
   </td>
   <td>Not accessed 
   </td>
   <td> 
   </td>
  </tr>
  <tr>
   <td>TimeCamp 
   </td>
   <td><strong>Yes</strong>  
   </td>
   <td> 
   </td>
   <td><strong>14</strong> 
   </td>
  </tr>
  <tr>
   <td>Targetprocess 
   </td>
   <td>No 
   </td>
   <td>Forum comments 
   </td>
   <td> 
   </td>
  </tr>
  <tr>
   <td>Deltek Vision 
   </td>
   <td>No 
   </td>
   <td>Contact support - email 
   </td>
   <td> 
   </td>
  </tr>
  <tr>
   <td>Favro 
   </td>
   <td><strong>Yes</strong>  
   </td>
   <td> 
   </td>
   <td><strong>15</strong> 
   </td>
  </tr>
  <tr>
   <td>Taskworld 
   </td>
   <td>No 
   </td>
   <td>Login required 
   </td>
   <td> 
   </td>
  </tr>
  <tr>
   <td>Everhour 
   </td>
   <td><strong>Yes</strong>  
   </td>
   <td> 
   </td>
   <td><strong>16</strong> 
   </td>
  </tr>
  <tr>
   <td>Clarizen 
   </td>
   <td>No 
   </td>
   <td>Login required 
   </td>
   <td> 
   </td>
  </tr>
  <tr>
   <td>Aiveo 
   </td>
   <td>No 
   </td>
   <td>Not accessed 
   </td>
   <td> 
   </td>
  </tr>
  <tr>
   <td>Kanbanchi 
   </td>
   <td><strong>Yes</strong> 
   </td>
   <td> 
   </td>
   <td><strong>17</strong> 
   </td>
  </tr>
  <tr>
   <td>CMiC 
   </td>
   <td>No 
   </td>
   <td>Not accessed 
   </td>
   <td> 
   </td>
  </tr>
  <tr>
   <td>Timely 
   </td>
   <td>No 
   </td>
   <td>Contact support - form 
   </td>
   <td> 
   </td>
  </tr>
  <tr>
   <td>Freedcamp 
   </td>
   <td>No 
   </td>
   <td>Free product &mdash; help blog 
   </td>
   <td> 
   </td>
  </tr>
  <tr>
   <td>Streamtime 
   </td>
   <td>No 
   </td>
   <td> 
   </td>
   <td> 
   </td>
  </tr>
  <tr>
   <td>Zenkit 
   </td>
   <td>No 
   </td>
   <td>No feedback 
   </td>
   <td> 
   </td>
  </tr>
  <tr>
   <td>Drag 
   </td>
   <td>No 
   </td>
   <td>Not accessed 
   </td>
   <td> 
   </td>
  </tr>
  <tr>
   <td>eXo Platform 
   </td>
   <td>No 
   </td>
   <td>Forum comments 
   </td>
   <td> 
   </td>
  </tr>
  <tr>
   <td>Adoddle 
   </td>
   <td>No 
   </td>
   <td>Not accessed 
   </td>
   <td> 
   </td>
  </tr>
  <tr>
   <td>Brightpod 
   </td>
   <td><strong>Yes</strong>  
   </td>
   <td> 
   </td>
   <td><strong>18</strong> 
   </td>
  </tr>
  <tr>
   <td>Flock 
   </td>
   <td><strong>Yes</strong> 
   </td>
   <td> 
   </td>
   <td><strong>19</strong> 
   </td>
  </tr>
  <tr>
   <td>RationalPlan 
   </td>
   <td>No 
   </td>
   <td>No feedback 
   </td>
   <td> 
   </td>
  </tr>
  <tr>
   <td>Flow 
   </td>
   <td><strong>Yes</strong> 
   </td>
   <td> 
   </td>
   <td><strong>20</strong> 
   </td>
  </tr>
</table>
_Table 3 - Online Help Systems Considered for Inclusion_
