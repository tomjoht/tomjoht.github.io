---
title: "Notes and discussion for Jonathan Warner's <i>More Than Words: How to Think About Writing in the Age of AI</i>"
permalink: /blog/warner-book-more-than-words-notes
date: 2025-04-15
categories:
- ai
- writing
- podcasts
keywords: ai book club, warner, ai
rebrandly: https://idbwrtng.com/warner-book-more-than-words-notes
description: "This post has notes and questions for discussion for <em><a href='https://www.amazon.com/More-Than-Words-Think-Writing/dp/1541605500'>More Than Words: How to Think About Writing in the Age of AI</a></em>, published in February 2025 by Jonathan Warner. Warner's book, which explores what we lose when we outsource writing to AI, is the first book in the <a href='https://idratherbewriting.com/ai-book-club/'>AI Book Club: A Human in the Loop</a>."
podcast_link: https://dts.podtrac.com/redirect.mp3/s3.us-west-1.wasabisys.com/idbwmedia.com/podcasts/warner_more_than_words.mp3
podcast_file_size: 51.7
podcast_duration: "59:40"
podcast_length: 51663964
---

* TOC
{:toc}

## Meeting recording

Here's a recording of the book club meeting, held April 20, 2025. 

<iframe width="560" height="315" src="https://www.youtube.com/embed/vUUQ6j7rNTo?si=INE-lDW8TrknT_Dm" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

For a transcript of the book club meeting, see [Meeting transcripts](#meeting-transcripts) below.

If you just want the audio, here it is:

{% include audio.html %}

(One video not enough? Here's the [recording of a smaller second session](https://drive.google.com/file/d/1HFSwEX2NhsvcQVEOsxoN__3rp29PG5q4/view), with only 3 people total.)

## Questions for discussion

* What types of content are worth writing with AI and not writing with AI?
* Does AI dehumanize the writing experience, removing writing as a tool for thinking and eliminating the emotional experience of wrestling with a topic?
* What value does technical documentation have in Warner’s view?
* Why doesn’t Warner explore the possibility of using AI to augment our writing?
* What do we lose when we use AI to write documentation?
* Are we still doing analytical, judgment-oriented, editorial/thinking tasks when directing AI with writing tasks and shaping outputs?
* Are there certain creative tasks related to documentation that we should keep human-produced?
* Why did I start an AI book club with a book that’s decidedly against using AI tools to write?

## Links

* My review: [Book review of Jonathan Warner's book *More Than Words: How to think about writing in the age of AI*](https://idratherbewriting.com/blog/jonathan-warner-more-than-words-book-review)
* Warner's substack blog: [The Biblioracle Recommends](https://biblioracle.substack.com/)
    * [Freedom's just another word](https://biblioracle.substack.com/p/freedoms-just-another-word)
    * [Horrors and Hopes](https://biblioracle.substack.com/p/horrors-and-hopes)

## Warner’s main arguments

* By "writing," the author mainly focuses on expressive writing. But Warner is pretty soured on almost all types of AI-generated content. In his mind, any writing that's worth doing is writing that involves thinking and feeling. Examples: essays, articles, books, etc. Not really targeting technical documentation in this book.
* Writing is a tool for thinking. If you outsource writing to AI, you're outsourcing your thinking to AI. It's a voluntary deskilling.
* Writing is a way to engage emotionally with a subject. You reflect on how you feel towards subjects and what you think about them. If you offload this to AI, you're removing the emotional component of writing. You're withdrawing some of what makes you human.
* What about the calculator analogy as support for AI? Warner says calculators empower students *to do more advanced math.* What does ChatGPT allow students to do? Are they doing more advanced writing? No, ChatGPT is doing the writing.
* Outsourcing writing to AI creates less intellectual momentum, as you no longer prompt your subconscious to continue working through problems (with the subconscious leading to random eureka moments in the shower, etc.).
* Writers are already paid little to nothing. Now the written word will be devalued even more. Will writing survive?
* Students are turning to ChatGPT to write essays because composition instruction in high schools and colleges have been stripped down to algorithmic rubrics that don't treat writing as exploration and a tool for thinking (e.g., a thesis must appear at the end of an intro; the intro should begin with an interesting fact or question, etc.). Students hate the formulaic essay structure and expectations, so of course they'll take an out (using AI) when presented with a workaround.
* Reading is similar to writing in that it involves thinking and feeling. Reducing everything to bullet points and summaries eliminates our engagement with texts. AI tools can't engage with a text, and you can't outsource that engagement to AI. If you're only dealing with high-level summaries and AI-rendered versions of text, you aren't engaging with those texts.
* ChatGPT isn't genuinely solving any problems and is only making things worse. What problem does ChatGPT actually solve?
* AI-generated content lacks the human substance of writing. It doesn't say anything notable, doesn't show a mind thinking, and lacks emotional engagement. There isn't a strand of a human wrestling with an idea and expressing a position. In short, AI-generated content isn't human.

{% include ads.html %}

## My reactions to Warner's book

* In terms of expressive writing, 100% agree. However, his view of "writing" seems to be too narrow. There's a lot of non-expressive writing. In fact, the bulk of what employees write in corporations is outside the scope of Warner's book. Not just technical documentation, but reports, procedures, policies, updates, etc. Much of this type of writing (professional writing) is ripe for AI automation. This is a point he fails to acknowledge other than making a few brief passing mentions in places (such as with the bilerate brain comments).
* I get the feeling that non-expressive writing isn't valuable in Warner's mind. To him, it's not real writing. If you're not thinking and feeling through subjects and articulating your thoughts/arguments in language, is it even a valuable activity? There's nothing in Warner's book that would suggest that this type of writing is valuable or worth doing. And yet, most of the reasons for reading are to gather information. For example, tax questions. Technical documentation. Reports, etc. Much of the informational content online (e.g., factual wikipedia articles). Much of this can be outsourced to AI.
* What if we outsourced non-expressive writing to AI, while reserving expressive writing for our own human-writing brains? (Is "expressive" writing even the right term here?)
* Warner doesn't acknowledge the ways in which AI tools might amplify and augment our writing. (I suspect he's never had to write technical documentation for something so complicated that only a senior engineer with years of experience in a subject domain can fully understand it.) Try writing that without AI to assist. You end up having to set up multiple meetings with [always busy] engineers, record the meetings, talk through whiteboard explanations, transcribe parts of the recording, etc. Even if you're not using AI to do the writing, AI can help understand and explain complexity in ways that are transformative for technical writers.

## Quotations from the book

(Content in brackets is summarized rather than quoted.)

"My students had been incentivized not to write but instead to produce writing-related simulations, formulaic responses for the purpose of passing standardized assessments." 5

"My students had been denied the deep pleasures of writing as a process through which you come to know your own mind." 6

"These people are alienated from the deep meaning and importance of writing as an act of thinking, feeling, and communicating…" 7

"It is frankly bizarre to me that many people find the outsourcing of their own humanity to AI attractive. It is akin to promising to automate our most intimate and meaningful experiences, like outsourcing the love you have for your family because going through the hassle of the times your loved ones try your spirit isn’t worth the trouble." 7

"Writing is an embodied act of thinking and feeling. Writing is communicating with intention. Yes, the existence of a product at the end of the process is an indicator that writing has happened, but by itself, it does not define what writing *is* or what it means to the writer or the audience for that writing." 8

"Writing is thinking. Writing involves both the expression and exploration of an idea, meaning that even as we’re trying to capture the idea on the page, the idea may change based on our attempts to capture it. Removing thinking from writing renders an act *not* writing." 11

"Reading and writing are inextricable, and outsourcing our reading to AI is essentially a choice to give up on being human." 11

"Effective accelerationism" = "a coalition of individuals gathered around a common belief that ‘artificial intelligence and other emerging technologies should be allowed to move as fast as possible, with no guardrails or gatekeepers standing in the way of innovation.’" 29

[Ethics is dismissed in the name of necessary progress.]

[We were getting along fine before ChatGPT &mdash; why waste all our water on it now? There’s an irony about using AI to solve climate change while the energy required to power AI hastens climate destruction.]

Alignment = "making sure the interests of the sentient and fully agented AGI are aligned with the interests of humanity." 37

Effective altruism = "artificial intelligence is the greatest threat to humanity." 38

[Are the upsides of AI worth the risks?]

[The calculator analogy = getting rid of the boring, mindless work. "Let’s acknowledge that Brynjolfsson lets the question of whether writing can ever be truly mindless go begging, while also setting the claim aside for the moment to probe the calculator/ChatGPT in more depth." 48

[Are you learning skills that will make you valuable in an increasingly automated world? "What is lost through the use of automation?" 49]

[Calculator analogy shortcoming: calculators empower students to do more advanced math. What does ChatGPT allow students to do? Are they doing more advanced writing? Not really, ChatGPT is doing the writing.]

"Allowing the machine to do that work, at least in theory, allows the human more time to grapple with the larger mathematical concepts and questions. It is making space for more thinking, not less." 51

[*Transhumanistic* arguments for AI argue that AI liberates us from human constraints.]

[Reading and writing engage us more than anything else. That’s why this technology is so threatening — the whole intellectual endeavor is at risk.]

"What I want to say about writing is that it is a fully embodied *experience*. When we do it, we are thinking and feeling. We are bringing our unique intelligences to the table and attempting to demonstrate them to the world, even when our intelligences don’t seem too intelligent." 58-59

[Warner sees writing as very Montaignesque. Montaigne saw his "essays" as trials, experiments with ideas that he would try to prove out. Writing is a tool for thinking through problems.]

"Writing involves both the expression of an idea and the exploration of an idea—that is, when writing, you set out with an intention to say something, but as part of the attempt to capture an idea, the idea itself is altered through the thinking that happens as you consider your subject. Anyone who has written has experienced one of these mini-epiphanies that is unique to the way humans write." 61

"When ChatGPT strings together its tokens in the form of syntax, it is not wrestling with an idea." 63

"Everyone has had the experience of walking away from a piece of writing, frustrated at their inability to capture the idea on the page, only to return to the task a day later and have a solution arrive as if by magic. This isn’t magic; it’s our subconscious working away while we’re doing other things." 63

"... something occurs to the writer, and there is an impulse or energy suggesting that this notion can be explored and expressed through language. Only then do sentences come into play." 65

"To write is to care about what has been written." 6

"Writing is inevitably a process of discovery for the writer." 66

[LLMs don’t consider the rhetorical situation (writer vs. audience vs. message).]

[What you write is a reflection of who you are, and that’s interesting and valuable to us as humans.]

[At some point, writing changes from thinking to communication and then the thinking part ends.]

"If writing is thinking—and it is—then it must be viewed as an act of our own becoming." 73

[Thinking changes who you are — writing is an act of becoming.]

[Even writing a book review, there’s an emotional component to writing it and weaving in quotes — writing that review makes you remember, reflect, and feel more than when using AI to assist with the writing.]

"As a fully embodied process, writing is not only thinking, it is also feeling. We conjure emotion through our writing, both in ourselves and in the reader." 76

[Writing is an act of reflection.]

"[ChatGPT] … has no trouble producing a statement that would pass public muster, while simultaneously saying nothing of consequence." 78

[AI language is so predictable and cliche as to lack all impact.]

"If we are going to resist this benumbing, we must be mindful that writing is feeling, and if nothing is felt when we are writing, we are missing an opportunity to connect to our own humanity." 81

[Pay attention to your emotions during writing. Writing engages you on an emotional level. There’s an emotional component to memory, reflection.]

"...even the most mundane writing occasions are opportunities for learning and benefiting from the experience of feeling as we write." 85

[You benefit from practice as a writer — when you outsource writing to AI, you lose the benefits of that practice.]

"Essentially, we develop best when we ignore that we’re trying to get better at something and instead just do a bunch of stuff that’s related to our big-picture goal. Our orientation should be around finding the best fit for our interests rather than relying on grit because that fit makes it much easier to be gritty." 100

"Hundreds of experiments show that people improve faster when they alternate between different skills." qtd in Warner. 101

[Make writing fun and people won’t be so eager to outsource the activity.]

"Reading is thinking and feeling in all the same ways as writing. Reading is a process that allows us to better understand the world and one another, sometimes even achieving something like virtual or alternate reality in our own minds as we join with the thoughts of others." 115

Qtd from George Saunders: "I think that what any of us pays for when entering into a reading experience is that feeling of seeing another mind at work, and not at work in a rational way. There’s something thrilling about seeing this other mind at work in this blissful and private and self-referential way, and then suddenly your mind joins it." 115

"...[quoting Sam Bankman-Friend] if you wrote a book, you fucked up, and it should have been a six-paragraph blog post." 119 

["bulletpointification of books", from Maris Kreizman’s term] 119

[Warner outsources some of his reading to ChatGPT so he can focus on more deep reading texts. Some researchers refer to a "biliterate" brain, "one that is both capable of the kind of skimming that characterizes reading the internet on screens and the deep reading that helps develop our critical thinking abilities." 120

[AI alters our relationship with the texts we produce.]

[AI can’t synthesize writing a book with personal experience, arguments, etc. (I'm guessing that one pushback against AI content will be to emphasize personal experience and perspectives as a way to underscore that our writing is human.]

[What problem does ChatGPT solve?] 130

"What if ChatGPT is not genuinely solving a problem but is instead being used to paper over a problem in a way that will cause significantly worse problems down the line?" 131

qtd in: "At the heart of education, at the heart of any learning, is engagement." 139

[The mode of identifying your gaps and then constructing a curriculum to fill the gaps is the engineering model of engagement, which is what Khanmigo is built on, and it’s shown to repeatedly fail.] "Learning is not about progressing along a continuum or even moving around a map. It is exploring in three dimensions. As a teacher, I have to be prepared for a student to zoom off in an infinite number of possible directions." 143 [You can’t expect students to progress straight linearly along a learning track. That’s not how engagement works.]

In his classes he tries to make sure that his students "are engaged in a ‘shared inquiry into the subject at hand.’ The goal is to have deep and rich experiences that spur students toward the kind of practicing of their practices that allows them to explore freely rather than move along a pre-mapped line." 146

"Rather than being a tool to gauge students' cognitive abilities, tests become an exercise in seeing how well you do on the test. this results in writing instruction that encourages students to work with templates - like the five paragraph essay - while writing according to prescriptive rules.. that are easily scored against a standardized scale but which have little to no relationship with the kinds of experiences that reflected genuine engagement with a challenge of writing inside a rhetorical situation." 150

"Seeing the capabilities of chatGPT, Michael W. Clune, an English professor at Case Western Reserve University, observed that the application generated "essays that meet all of the official criteria for student writing: they have a thesis; they are polished, coherent, and well-argued; they support their points with evidence. They also lack any trace of surprise or originality, make no new connections, and are devoid of any striking use of language or evidence of individual human sensibility." 151

"... the most important factor in terms of the quality of a student's output and the depth and breadth of their learning was how interested they were in the task at hand." 159 

"Unlike the featureless text that chat GPT turns out, human writing is spiky, weird, and messy. This is particularly true when we are in the midst of trying to figure stuff out through writing, which is always going to be the case with students. if I wanted my students to become confident writers I had to let them write, and if I was going to let them write, I had to Value something other than the ability to BS proficiently." 164

"We don't only need to teach children to read, we need to *make* readers." 169 

"Writing is a tool by which we can experience and understand both ourselves and the world at large. I realize that there are people of different minds about this, but to me, that is the core purpose of education, and I’ve conducted my courses in accordance with those beliefs." 191 

"The first draft is the *most* important part in terms of human involvement because it establishes the intention behind the expression." 219 

"Synthetic text production is a performance of writing, not writing itself. Without having generated a draft from the fuel of my own thoughts, it made no sense to even try to revise or edit that text into a satisfactory column. it would take less time to start from scratch, and I would wind up with a better product." 219

"Rather than pivoting, I believe we have to orient toward goals that are associated with human flourishing, and make use of artificial intelligence where it is useful in those goals and reject it where it is a hindrance." 227 

"If ChatGPT can do it, it's probably not worth doing by humans, and it very well may not be worth doing at all." 241 

"In my view, the goal is to create ourselves as individuals through acts of personal discernment. To practice our taste and express our values. We bring these individual selves into communities of other individuals who have their own unique world views. Here, then, is an ecosystem of interdependent individuals, a collection of intelligences existing without being flattened into an algorithm." 264

"I can testify that writing involves a wonderful kind of difficulty in which our grasp continuously falls short of our reach. I am mere moments from wrapping up the bulk of my work on this book save the inevitable fine-tuning of the editorial process, and because writing is thinking and feeling as part of an embodied process, I am experiencing a kind of buzzing sensation in my head in my hands as my body senses the end of a long, intense process. what a privilege it has been to put every ounce of myself into the effort." 279

"Our individual ends are assured, but along the way to that inevitability, we should at the very least give ourselves the best chance possible to *live.*"* 280


## Meeting transcript

Here's a transcript of the book club meeting. (Note: This transcript was cleaned up and made more readable with AI.)

**Attendees:** Tom (Host), Mette, Superja, Sherry, Amy, Daniel, Frank, Molly, Peg

* **Tom:** Let me briefly introduce the book club before we dive into the discussion. I've been running book clubs at work for a few years on different topics, mainly automotive and transportation, which is my documentation domain. I've found that reading has a positive effect, helping me engage at a deeper level and pulling me away from the ubiquitous short-form content, allowing for more thoughtful consideration.
* AI is everywhere now, saturating conversations, but finding material that goes deep can be challenging. Much of the news focuses on company announcements or new models. I wanted to find books exploring AI in depth. We started with Jonathan Warner's book because it was one of the few directly addressing *writing*, although much of it isn't technical writing. Even so, it touches on aspects relevant to us as writers. Any high-level questions about the book club before we begin?
* I'm based in Seattle, been here four years, previously in Santa Clara for about eight. I work at Google now, before that Amazon and some startups. While we might frame discussion around technical communication, feel free to bring in any angle you find interesting.

**(Initial Reactions to the Book)**

* **Tom:** To kick off, what were your high-level thoughts on the book? Did you like it, dislike it, and why?
* **Mette:** I thought it discussed *how people learn to write*, which makes sense given Warner's background in education. He made good points about that and the potential impact of AI. Where it felt lacking, likely intentionally, was its discussion of technical communications and business writing. He lumps these under the term "content," seemingly derisively, distinguishing it from what he considers "true writing"—writing with expression, feeling, and human thought. He relegates "content" to a bin that doesn't require feeling and implies AI can handle it, though he didn't elaborate much. I was looking for that discussion and didn't find it, but I still enjoyed his points, especially on critical thinking.
* **Tom:** That's an astute comment. He does seem to pigeonhole "writing" as primarily expressive, emotional, argumentative work. Yet, much writing—business, technical, policies, procedures, Wikipedia articles—isn't that. Expressive writing might even be a minority. A lot of paid writing is informational and factual. (Notes a chat comment agreeing with Mette).
* **Daniel:** I really enjoyed reading it and was generally sympathetic to his views. As someone who has taught college English, I know how difficult it is to teach writing to young adults, and I've seen the decrease in students wanting to engage with reading and writing, especially post-pandemic. I believe this fuels his anxiety. He touches on the difference between an experienced writer using AI versus students who haven't learned to write yet, highlighting the risk of "deskilling," which I found poignant. I agree he doesn't cover procedural or technical writing much. I'm interested in what others think he gets *wrong* about AI, not just what he missed.
* **Tom:** It's valuable that you have empathy for his anxieties from your teaching background. We'll come back to your great question: What does he get wrong about AI?
* **Frank:** I have contradictory feelings. I enjoyed the book but was often irritated by it. The irritation often came from a "slippage" in terms, especially "writing." I wasn't always sure what type of writing he meant, as it seemed to shift. The book felt a bit scattershot, despite the complexity of the topic. The inclusion of many personal anecdotes made it feel somewhat like a memoir, perhaps padded out—it could have been a long article. Especially in the first half, I found it hard to pin down his exact arguments or definitions (of AI, of writing). Sometimes his point that "ChatGPT can't write like a writer" felt obvious and repetitive. It's funny because I sound critical, but I actually enjoyed it and generally agreed with him—he was preaching to the choir. Yet, I felt the argument sometimes went in circles.
* **Tom:** Great insights. Many technical writers have both creative and business writing sides. Warner's arguments might speak more to the creative side. The lack of a clear definition for "writing" does make his points feel slippery.
* **Amy:** Having also taught in higher education, I felt Warner was very clear about who he is and his perspective—an academic. Tom, you were also clear: this book isn't about industry writing. Warner highlights the academia-industry divide. Many PhDs entering industry face a shock regarding the pace; the "romantic idea of writing" Warner discusses thrives in academia's luxury of time, whereas industry demands delivery "yesterday" with "good enough" sentences. I had no expectation he'd cover industry writing.
* I thought he clearly articulated that these AIs (LLMs) don't *write* in the human sense; they generate text based on probabilities. His central idea&mdash;writing is thinking, and AI doesn't think&mdash;is a powerful point, a "sword" we can use to articulate our value and argue against being replaced by AI agents.
* He also raised another crucial point: we all honed our skills through labor ("sharpened our knives on the rod of labor"). If students no longer learn to write manually, who will replace us when we retire? Will the next generation have the necessary skills? As an educator responsible for supplying future hires, he asks an interesting question. This felt like the bridge between his concerns and ours in the industry. Those were my two big takeaways.

**(Writing as Thinking & AI's Role)**

* **Tom:** Excellent points from everyone. Let's explore the "writing is thinking" idea, stemming perhaps from Montaigne using writing to test ideas. When using AI for work, like documentation, are you still "thinking"? For me, it *is* thinking, but different&mdash;less rigorous, more "Meta-thinking" about accuracy, structure, relevance. It's not as taxing as writing from scratch. What are your experiences?
* **Molly:** I feel they are different. My thinking when writing without AI is more "primordial and ugly," but potentially more powerful. When I use AI, maybe for polishing, it's more high-level judgment, like "rubber ducking."
* **Daniel:** I agree thinking happens when using AI. Creating a draft with AI doesn't necessarily save time, but it saves "cognitive bandwidth"&mdash;it feels easier. Writing from scratch feels more rigorous. When experimenting with AI for creative writing, the output often feels "flattened" and uninteresting to me. Warner emphasizes intentionality and agency, which AI lacks. So yes, thinking occurs with AI use, but it's not the same kind.
* **Tom:** You phrased it well: saving "cognitive bandwidth." It's less rigorous, less "primordial." We're approving, editing, making judgments, rather than the taxing effort of articulating fuzzy ideas into language from scratch, which requires more intentionality.

**(What Does Warner Get Wrong? Inevitability Debate)**

* **Tom:** Let's return to Daniel's question: What does Warner get wrong about AI? We just discussed whether he's wrong about thinking not occurring with AI use. Any other disagreements?
* **Daniel:** I didn't have strong disagreements; I thought he got a lot right. I was more curious how people who are *pro*-AI would argue against his points about exploitation, climate impact, etc., or even the nuts and bolts of using ChatGPT.
* **Tom:** This connects to the industry pace versus academia. Warner argues against the inevitability of AI adoption at the end of the book, suggesting we can curtail technologies, citing examples like nuclear weapons. I tend to disagree here. I think the adoption of powerful technologies *is* often inevitable. The next book we're reading, "The Coming Wave," explores this. My prediction is that technical writers who reject AI won't remain competitive in terms of speed, accuracy, and possibly long-term quality. I lean towards the inevitability camp.
* **Amy:** Mette pointed out in the chat that Warner *does* acknowledge AI's potential for rapid improvement, suggesting current awkwardness might be temporary. Mette also brought up genetics as an area where society *has* exercised restraint ("just because we can, doesn't mean we should").
* **Amy:** I don't see it as purely binary&mdash;either reject AI completely or embrace it for everything. I appreciate Warner prompting critical thought: *Do* we need AI for this specific task? Is it the best tool? Is the cost (e.g., environmental impact, like water usage in Kenya) worth it? He asks us to think critically about *when* and *how* we use it. A handwritten letter can have more impact than an email. Critical thought belongs to us, not the AI.
* **Tom:** Caveat: While I use AI heavily for technical docs, I agree it doesn't work well for my creative writing attempts (like blog posts).
* **Amy:** Right. As Mette noted, he doesn't fully address our industry realm. This book serves more as an existential conversation starter. But his call to think critically about *when* AI is needed is valuable.
* **Sherry:** This reminds me of the internet's rise in the 90s. Once novel, now indispensable for writers and non-writers alike. AI seems headed in that direction. It will do some things well (speed) and others poorly. The point is to use it wisely for tasks it's suited for, recognizing that other tasks require human capabilities. We need the wisdom to know the difference and use it as an appropriate tool.

**(Reading vs. Skimming & Content Generation)**

* **Superja:** He discussed *reading*, distinguishing quick reads/skimming from deep reading. He mused about using AI to outsource "short reading." This reminded me of Tom's point about using AI for simpler *writing* to save time for complex tasks. He hinted at a similar analogy, but applied it to reading.
* **Tom:** His points on reading as an act of thinking and feeling were unique. It contrasts sharply with trends like the Sam Bankman-Fried quote about the "bullet pointification of books"&mdash;a startling push towards summaries over engagement.
* **Frank:** I haven't needed AI for work tasks yet. Personally, I use it sometimes for research&mdash;getting quick summaries on unfamiliar topics for blog posts, but I always rewrite heavily. I encountered a "chilling" YouTube video demonstrating a workflow: generate a post with ChatGPT, use "Humanize AI Pro" to make it sound less robotic, then use "Quillbot" (an AI detector) to ensure it passes as human. Using multiple AIs to essentially fool readers seemed "crazy," though I understand the pressure for freelancers to generate content quickly (the video claimed "blog post in 20 minutes"). It was a frightening wakeup call that these tools exist.
* **Molly:** That's fascinating. I don't know how I could do that; I wouldn't feel I understood the content enough to stand behind it. Maybe I'm just a "bad bullshitter." It's amazing how people carry that off.
* **Tom:** This connects back to Warner's negative association with "content"&mdash;not thoughtful writing, but mass-produced material. It's ironic because "content" is often used neutrally or positively in tech comm (content strategy). Now it risks being associated with low-quality, generated writing.

**(AI, Language & Cultural Considerations)**

* **Amy:** Yes, I was surprised by his bitterness towards the word "content." Picking up on a chat comment (from Sherry?) about preferences for audiovisual content, and Frank's point: Warner's book is very Anglocentric. I wonder how many of his students are non-native English speakers. For people I work with who aren't English-dominant, these AI tools are incredibly helpful for clearer communication and collaboration. Why wouldn't we take advantage of that? This angle was missing. Also, the AI detection tools Frank mentioned seem part of a possibly misguided battle in higher ed, missing the point about multicultural teams and effective communication.
* **Tom:** Teachers face immense difficulty now&mdash;how to allow helpful AI use (like language smoothing) without students bypassing learning? Lack of clear solutions leads many to ban tools, even as things like Grammarly become more AI-powered. I agree with Amy's point on English dominance; AI making non-native English sound fluent *could* be a threat to native English writers (outsourcing), though we haven't seen that widely yet.

**(The Next Generation of Writers & Deskilling)**

* **Tom:** Let's revisit Amy's point: Will the next generation, raised on AI, lack fundamental writing skills? Or will they be "digital natives" amplified by these tools?
* **Daniel:** Deskilling students isn't good, but they *will* become proficient users of AI for writing tasks. My anxiety isn't just about skill loss, but that *culture will change*, devaluing writing itself. Visual culture (TikTok, social media) might become dominant, similar to how visual iconography served pre-literate societies. I fear a broader, potentially "bleak" or "dystopian" cultural shift more than a simple skills gap.
* **Amy:** Daniel's point about cultural shift is compelling. In the near term (next 5 years), we already see generational clashes (Gen Z vs. others). We're responsible for hiring and nurturing the next wave, who may have different training and standards. Can they meet our current job descriptions? Do we *want* them to replicate our skills, or overhaul them completely? How do we navigate this if their fundamental training differs?
* **Tom:** I confess I haven't thought deeply about training the next generation. I see anxiety from early-career writers (on Reddit, etc.) questioning the career's future. Will tech writing exist in 5 years? There's also the "steeper entry point" issue: AI might automate junior tasks (e.g., glossaries), requiring new hires to handle senior-level work immediately, bypassing the traditional learning curve. Maybe I'm overly influenced by "accelerationists," but the change feels rapid.

**(AI Use at Work & Augmentation)**

* **Tom:** How many people have access to AI tools at work? (Most indicate yes). Daniel, you asked about my work: AI use isn't mandated from management. There's a subgroup of enthusiasts (we have a study group), but many other tech writers might be apathetic, lack time, or use tools quietly. I need to survey to get a real sense. I'm personally a "maximum user," partly because I enjoy experimenting.
* Tying back to Warner: I think he overlooks AI's potential for *augmentation*. Much discussion focuses on automating existing tasks, not enough on enabling *new*, more complex work, which is where I try to focus my AI use&mdash;tackling things I couldn't do before.
* **Daniel:** I agree. In Warner's "resist, renew, explore" framework, "explore" seems limited to *talking about* AI publicly, not *exploring its use* in writing practice. This creates tension for those who sympathize with his concerns but also want to use AI productively.
* **Tom:** That tension is part of the book's value, starting with a somewhat anti-AI text forces us to confront how AI challenges our skills and authority&mdash;a long-standing issue in tech comm intensified now.
* **Molly:** Picking up on "resist"&mdash;Warner suggests resisting the "economic model of thinking." How can professional writers realistically do that when writing is their livelihood?

**(Economics, Creative Spirit & Warner's Practice)**

* **Tom:** Warner paints a bleak picture of creative writing economics (newsletters being key, books not paying). Yet, people write creatively regardless of pay, driven by an innate desire. I think this creative spirit will persist. Warner's own Substack ("Biblioracle") shows him practicing intentional, thoughtful writing. I firmly believe writing is a tool for thinking (my blogging experience confirms this: ideas flow when writing is exploration). I want to preserve that aspect personally, while using AI pragmatically for work where needed, still applying strategic thought.

**(Logistics & Next Book)**

* **Tom:** Quick logistics check: Preferred time on Sundays? 10 am or 5 pm PST?
* **Amy:** Just stick to your plan; people will come if they can. You having the whole year planned is impressive!
* **Tom:** Okay, I'll likely stick to 10 am PST, as I'm fresher then. I'll probably drop the separate Australia time slot.
* Speaking of planning, the next book is "The Coming Wave" by Mustafa Suleyman. He co-founded DeepMind. It's well-written, very thought-provoking, and relevant. It's generally pro-AI but focuses heavily on containment issues.
* **Amy:** My spouse read it and thought it was great, a "regular person's endorsement." He found it connects AI to many facets of life.
* **Tom:** Yes, books like these often go much deeper than online articles. It seems we'll have a good discussion about this broader phenomenon.

**(Conclusion)**

* **Tom:** Okay, let's wrap up. Thanks again for coming, everyone, it was great meeting you all. The discussion quality was fantastic. I'll post the recording link on the book club page. Have a great rest of your evening!
