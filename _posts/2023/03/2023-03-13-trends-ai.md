---
title: "The influence of language-generative AI tools on tech comm: parlor tricks or disruption?"
permalink: /trends/trends-to-follow-or-forget-language-generative-ai.html
categories:
- ai
keywords:
rebrandly: https://idbwrtng.com/trendsaitools
series: "Trends to follow or forget"
sidebar: sidebar_fizzled_trends
description: "This post is <a href='/trends/trends-to-follow-or-forget-intro.html'>part of a series</a> that explores tech comm trends that I've either followed or forgotten, and why. The overall goal is to better understand the reasons that drive trend adoption or abandonment in my personal career. This post focuses on language-generative AI tools, such as ChatGPT and others."
---

* TOC
{:toc}

## What are language-generative AI tools?

Some AI language tools first started appearing in word processing tools like Google Docs' Smart Complete, which predicts the right words to finish your sentence. In late 2022, many AI image generators began emerging, such as DALLE and Midjourney. These image generators create images based on text prompts rather than requiring you to use graphic tools like Illustrator. 

The recent wave of mainstream AI tools includes natural language generators like ChatGPT. These language generators can compose articulate, coherent text on virtually any topic, including code samples and documentation-like content. The ability of AI to craft human-like language is new. In a _New York Times_ article titled ["A.I. Is Mastering Language. Should We Trust What It Says?"](https://www.nytimes.com/2022/04/15/magazine/ai-language.html) Steven Johnson explains:

> ... GPT-3 and its peers have made one astonishing thing clear: The machines have acquired language. The ability to express ourselves in complex prose has always been one of our defining magic tricks as a species. Until now, if you wanted a system to generate complex, syntactically coherent thoughts, you needed humans to do the work. Now, for the first time, the computers can do it, too. Even if you accept the Gary Marcus critique &mdash; that the large language models simply present the illusion of intelligence, a statistical sleight of hand &mdash; there’s something undeniably momentous in the fact that we have finally met another magician.

In other words, these large language models can process large amounts of data and generate a linguistic output that is syntactically accurate, often passing the Turing Test. This means that computers now have the ability to understand, process, and generate complex language&mdash;something that seemed a human-only capability, until now.

<figure><img style="max-width: 500px" src="https://s3.us-west-1.wasabisys.com/idbwmedia.com/images/aibotswritinglots.jpg" alt="AI bots writing content at 10x the pace" /><figcaption>AI bots will accelerate the amount of content online</figcaption></figure>

Some tech analysts are on the fence about whether tools like ChatGPT are simply performing “parlor tricks” or whether they can disrupt the way the internet works. We probably won't know for a couple of years. One obstacle to disruption is that AI tools tend to hallucinate, inventing facts and other details. (The best way to prompt hallucination is by asking ChatGPT to write your bio.) Sometimes, there are often so many inaccuracies that fixing them takes longer than creating the content yourself. _De-hallucinating_ these tools isn't an easy fix, apparently, because they are prediction engines, not web scrapers. 

{% include ads.html %}

Some other AI tools sidestep the problem of inaccuracy by focusing mostly on language editing from content you supply. One of these tools is [Wordtune](https://wordtune.com/), which uses AI to help with editing and rewriting existing content rather than generating all content from scratch. Wordtune recently added “spices,” which are AI features that allow you to generate more content if desired, such as expanding on an existing paragraph or providing examples.

<figure><img src="https://s3.us-west-1.wasabisys.com/idbwmedia.com/images/wordtunescreenshot.png" alt="Wordtune's spices" /><figcaption>Wordtune incorporates AI tools to expand or shorten content</figcaption></figure>

Unlike ChatGPT, which just takes over the entire content, Wordtune works more like Grammarly but with some optional AI features added in. 

In my experience, leveraging AI tools with writing involves a mix of human and machine input. For example, you crank out a first draft on your own, then maybe augment some details through AI as well as fix the language. After that, you make more human edits for composition, organization, and flow. You might then let the AI take another pass at the language to smooth out the changes. Then you manually read and make adjustments again. 

In other words, writers will leverage AI tools to help in the writing process, not abdicate the entire writing to machines. (Every time I try to abdicate the writing process to AI, the outcome fails. In writing this post, I did use Wordtune, ChatGPT, and other AI tools to try to help move this post along, similar to the process I described here.)

In another market corner, some language AI tools [Copy.ai](https://copy.ai) and [Jasper.ai](https://jasper.ai) emerge to help content marketers. Both tools promise to help you write 10x faster. Copy.ai promises to “cut writing times by 80% so you can focus more on the projects you love.” Most people groan when seeing these tools. The assumption is that hacks will push out SEO-optimized content garbage, making articles that are full of keyword-optimized general statements and bland clichés to clutter up search results. As such, these tools will place more challenges on search engines to identify and avoid this content.

## AI's strengths: exposition, not argumentation

Playing around with ChatGPT, I've noticed that AI-written content has a certain veneer to it: its style is almost always expository, with generalized language and a muted tone. The content is more explanatory than argumentative. 

Human-written content, by contrast, is more opinionated. Humans tend to take a stand on an issue, conjecturing a thesis. Humans are more likely to offer an original idea, with personal experiences interwoven into an argument. It's something you won't find AI tools generating. AI tools generate content that reads more like an encyclopedia article. Like background information or an information brief.

AI's excellence with exposition might mean that while AI can't write blog posts, personal essays, or novels that readers find engaging, they might do a decent job at technical communication, which usually lacks voice, doesn't present original ideas or assertions, and is utilitarian in nature. Users of technical documentation want to understand a complex technical concept, not be enlightened by a pundit's insights on the latest issues. As such, AI tools might displace technical writers, medical writers, and science writers more quickly than creative writers. 

Add in the fact that AI tools are excellent at reading and articulating code, and it all makes technical writers prime candidates for displacement. 

Perhaps the only saving grace is that technical writers spend only a fraction of their time writing documentation. (For example, I've been working on putting together an enormous documentation project plan for the past two weeks.) Also, much of the documentation we are writing is content that doesn't exist, for features and tools being in development. As such, language models won't have this documentation in their training set yet. What perhaps AI can do is take existing engineering babble and convert it into more readable content.

As an example of how AI can convert jargon into readable prose, consider this MRI report, which someone [posted on Reddit](https://www.reddit.com/r/FootFunction/comments/zix030/my_recent_mri_report_after_a_foot_injury_any_idea/) asking for an explanation.

<figure><a href="https://www.reddit.com/r/FootFunction/comments/zix030/my_recent_mri_report_after_a_foot_injury_any_idea/"><img src="https://s3.us-west-1.wasabisys.com/idbwmedia.com/images/mri-report-sample-reddit.png" alt="Confusing medical jargon" /></a><figcaption>AI tools can convert this medical jargon into an easy-to-understand report for laypersons</figcaption></figure>

I converted this image to text and asked ChatGPT to provide an easily understandable explanation (at a 5th grade level). Here it is:

> This report is about an MRI scan that Mr. Lee had on his right foot. The scan used different techniques to take pictures of his foot from different angles.
> 
> The report shows that Mr. Lee has some thickening in the ligaments in his foot. Ligaments are like elastic bands that hold bones together. This might be because he had a sprain, which is when the ligaments get stretched or torn.
> 
> The report says that there are no broken bones or other problems with the shape of his foot. But there is some fluid in one of his joints, which might mean that it's a little swollen.
> 
> The report also says that there are no problems with the blood vessels in his foot, which is good news. The doctor who wrote the report recommends doing some more tests to learn more about Mr. Lee's foot.
> 
> Overall, the report tells us that Mr. Lee's foot is healing from a sprain, and it's important to keep an eye on it to make sure it gets better.

This version might be simplified a bit too much, but you get the point: language-generative AI can help transform highly technical gobbled-gook into readable text. Imagine a scenario where the whole MRI process is conducted by non-technical staff. The scans are interpreted by AI (which does a great job at pattern matching in images), and the analysis is transformed into readable language by AI language generators. The doctor just stands by to rubber stamp the result and answer any follow-up questions. 

This is one way that AI will disrupt entire professions, not just technical communication. This scenario could apply to any industry with technical jargon. And if AI tools can translate complex language into simple, understandable text, where does that leave technical writers?

## Leveling the playing field for all types of writers

AI's ability to construct and shape language will undoubtedly impact the tech comm profession, since it will help many non-writers overcome their inexperience with grammar and style. Consider the case of a tech worker who speaks English as a second language yet who has strong technical experience. These language-weak-but-tech-strong writers will likely be empowered with AI-assisted writing tools to fix all the poor wording choices and other awkward constructions that have held back more acceptance of their content.

At the same time, consider a writer who is tech-weak-but-language-strong. This writer might simply use AI to generate summaries of code, or to create code samples automatically, and navigate other technical details. These writers could ask AI tools to translate technical jargon and explain needed programming concepts in language a second-grader could understand. In short, AI tools have the potential to level the playing field for both types of writers. 

In both cases, the labor pool of potential tech writers could widen, allowing tech writers to fill roles competently even if they lack a mastery of the language or don't have strong technical skills. 

## Why I'm experimenting with AI

In the past couple of months, I've experimented with ChatGPT and other artificial intelligence tools quite a bit. I’m open to enhancing my output with AI tools for several reasons. First, I know that if I’m competing based on my ability to construct coherent sentences, it will be a losing battle. I want to leverage AI-assisted tools so that I can stop worrying about typos and awkward constructions and instead focus on the more substantial aspects such as story, shape, and flow. I don’t want to be spending my time editing and proofreading manually while others use machines to do the same thing in minutes. Someone once told me that when he reads my content, the typos "attack him." Strange, yes, but if I can avoid language errors that jar readers, all the better.

As a result of AI-assisted writing, our productivity might be higher. Those who reject AI tools might find themselves on a horse-and-buggy trying to compete with fast-driving cars along a highway. I’d like to be able to create an intelligent blog post in a couple of hours, with interesting insights, eloquent language, and other characteristics of engaging content. I'd like to crank out documentation much faster too, finishing entire projects in a few days.

In Cal Newport’s _Deep Work_, Newport says one characteristic of successful people is the ability to “work well and creatively with intelligent machines” (28). He explains:

> As intelligent machines improve, and the gap between machine and human abilities shrinks, employers are becoming increasingly likely to hire “new machines” instead of “new people.” And when only a human will do, improvements in communications and collaboration technology are making remote work easier than ever before, motivating companies to outsource key roles to stars—leaving the local talent pool underemployed. (23)
> 
> ...those with the oracular ability to work with and tease valuable results out of increasingly complex machines will thrive. Tyler Cowen summarizes this reality more bluntly: “The key question will be: are you good at working with intelligent machines or not? (24)
>
> ...In this new economy, three groups will have a particular advantage: those who are best at what they do, and those with access to capital.” (28)

In other words, smart people use tools to augment their capabilities. Many of the tools require sophisticated inputs and other training to use. For example, while it’s easy to use ChatGPT and get more savvy with sophisticated prompts, learning how to actually train and manipulate language models toward desired ends would be a high-value skill set. If you can manipulate language models, that might be a skill that allows you to steer and tame this tools to be more useful.

## The loss of authorship

Although this might be more of an emotional hurdle than anything else, and more related to my blog than work projects, I worry about losing my sense of authorship when using AI tools. If the output doesn't feel like my own voice, how will that change my relationship with writing? 

Additionally, it might be challenging to keep a consistent writing style when integrating content from AI-assisted tools. When you generate a sentence through AI and mix it with your own, the tone and flow becomes more hodgepodge. 

However, I suspect readers care less about authorship than the writer. The reader wants well-written, interesting content and would likely welcome any tools that make the outcome more likely.

Also, companies are not worried about maintaining a byline for technical documentation. If tech writers can safely leverage AI tools to enhance their professional output, companies likely won't object. In fact, companies would likely applaud the feat. _(Hypothetical example... Me: "Hey boss, I used AI to create this documentation in half the time." Manager: "Great job, Johnson! Now, can you figure out a way to do it in a quarter of the time, while taking on a second project?")_

## But writing is only a fraction of the job

Regardless of how advanced these tools get, writing constitutes only a fraction of the larger job of tech writing. Some writers even say they spend only 10% of their time actually writing documentation, and thus dismiss the impact of language-generating tools (especially given the inaccuracies of these tools). 

But AI tools can do more than just write. They can create code samples, brainstorm outlines, critique and review existing content, summarize long content, suggest reference sources, and more. We might just be figuring out the most effective use cases for AI tools in tech comm. The following applications might be useful:

* Simulating reader responses to documentation based on personas
* Mining through hundreds of support tickets to identify trends
* Identifying actionable insights from analytics data points from readers
* Identifying the impact of the latest release on hundreds of existing documentation pages, including code samples.
* Comparing API documentation against a best practices template and identifying areas of inconsistency.
* Highlighting terms that are similar (almost synonyms) but used in variable ways.
* Auto-populating field definitions based on code files and other source documentation.
* Generating code samples and ensuring they are up to date with the latest changes. 
* Automatically linking related topics in the documentation for easy navigation.
* Leveraging natural language processing to provide personalized search results.
* Automating the creation of tutorials and videos to guide users through the product.
* Automatically recommending content tailored to the user’s profile, preferences, search history, and browsing history.

I think tech comm tools will incorporate more of these automated AI features into their tool suites, offering a kind of tech comm copilot. Whatever the advancements, tech writers will probably work _with_ AI tools (at least in the immediate future), rather than being displaced by AI tools.

## Current status

We’re at the start of a rapid expansion of AI tools and applications. It’s too early to know what outcomes will result, but tech writers should stay aware and explore these tools. It’s likely that if search evolves to AI language queries, expectations will follow for documentation as well. 

## Takeaway

{: .tip}

AI-based language generation tools can reduce the need for language expertise, evening the playing field for both writers and non-writers to create documentation.

## Next post

Continue to the next post in this series: ["Trends to follow or forget" presentation to STC India](/trends/trends-to-follow-or-forget-presentation-stc-india.html).
